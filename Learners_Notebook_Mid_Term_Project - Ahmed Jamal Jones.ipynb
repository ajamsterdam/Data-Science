{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A5on_E9xQSC"
      },
      "source": [
        "<center><p float=\"center\">\n",
        "  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n",
        "</p></center>\n",
        "\n",
        "<h1><center><font size=10> Generative AI for NLP Program</center></font></h1>\n",
        "<h1><center> Project </center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkypp72Oa4LD",
        "tags": []
      },
      "source": [
        "# **GA-NLP Mid-Term Project: Financial Product Complaint Classification and Summarization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exBRHi0DbHFT",
        "tags": []
      },
      "source": [
        "## **Business Context**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJfHP45hZpwW",
        "tags": []
      },
      "source": [
        "### **Description**\n",
        "*In the modern financial industry, customer complaints play a crucial role in identifying areas where financial institutions can improve their services. Effectively categorizing these complaints into specific product categories, such as credit reports, student loans, or money transfers, is essential for addressing customer concerns promptly by routing the tickets to relevant personnel. Leveraging Generative AI for text classification can help financial institutions better understand customer grievances and respond more efficiently. Apart from this, a summary of the customer complaint helps the support personnel quickly grasp the gist of the grievance*\n",
        "\n",
        "### **Objective**\n",
        "*The primary goal of this project is to utilize Generative AI techniques to improve the classification and summarization of customer complaints in the financial sector.\n",
        "Specifically, the project will focus on:*\n",
        "\n",
        "1. **Text-to-Label Classification:** *Implementing Zero-shot and Few-shot prompting methods to accurately classify customer complaints into relevant product categories.*\n",
        "2. **Text-to-Text Summarization:** *Using Zero-shot prompting to generate concise summaries of customer complaints, enabling more personalized and effective responses.*\n",
        "\n",
        "### **Conclusion**\n",
        "*Upon completing this project, you will have the capability to develop solutions for LLM-based text classification and summarization. These tools will enable financial institutions to automate the complaint handling process, leading to faster, more accurate responses to customer issues, improved customer satisfaction, and enhanced compliance with industry regulations. This project will also provide you with valuable skills and experience that can be applied to a range of real-world business challenges.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na6DoDeQBIbn",
        "tags": []
      },
      "source": [
        "# **Section 1 : Setting Up for Prompt Engineering with Mistral Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcGMygn3_Mq9",
        "tags": []
      },
      "source": [
        "### **Install & Importing neccessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y ninja-build cmake\n",
        "!pip install ipywidgets --upgrade"
      ],
      "metadata": {
        "id": "REVTReY_day6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6ea2a4-21d9-4343-a43f-d90c45836338"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ninja-build is already the newest version (1.10.1-1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.5)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "EM8UTzsidgXe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k55ATwppBVZj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This part of code will skip all the un-necessary warnings which can occur during the execution of this project.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kHfXSmivkKPb",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1c9f2a-707d-4b70-c311-d4722e67d154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python==0.2.69\n",
            "  Using cached llama_cpp_python-0.2.69.tar.gz (42.5 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.69)\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (3.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.69) (3.0.2)\n",
            "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.69-cp311-cp311-linux_x86_64.whl size=55261174 sha256=232c0583132597c375441b79b56b88c3f67edb93abf437d467f0fede3b364035\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/ff/b4dba97fbd16e731705b262602ba8f3b672bf4bde54ea0c104\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.69\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "# Installation for GPU llama-cpp-python==0.2.69\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python==0.2.69\n",
        "# For downloading the models from HF Hub\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sq81SmRht8r_",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f960da0-2d5f-41c6-a20b-9293e07562ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Using cached multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.47.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert-score\n",
            "Successfully installed bert-score-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!pip install bert-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yBAX7X_aK3Ff"
      },
      "outputs": [],
      "source": [
        "!pip freeze > requirement.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TsrUPUGTANTi"
      },
      "outputs": [],
      "source": [
        "# Basic Imports for Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import evaluate\n",
        "\n",
        "# from google.colab import drive\n",
        "import locale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdQdNav7AOtV",
        "tags": []
      },
      "source": [
        "### **Question 1: Importing Libaries and Mistral Model (3 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO7TfAEiSxMR"
      },
      "source": [
        "- For the Mistral Model name or path and model basename, refer to the **Week 3 Additional Content: Prompt Engineering Fundamentals**\n",
        "- Code Notebook: Self-Consistency and Tree-of-Thought Prompting with Llama 2 and Mistral.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/blob/main/mistral-7b-instruct-v0.2.Q5_K_M.gguf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cpQlIfeqAkvz"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e9c3ISlwftKB"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
        "model_basename = \"mistral-7b-instruct-v0.2.Q5_K_M.gguf\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\",\n",
        "    filename=\"mistral-7b-instruct-v0.2.Q5_K_M.gguf\"\n",
        "    )"
      ],
      "metadata": {
        "id": "9iTSfdfVYHPC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "70ab1170a3d14723b8fa2bca67322e29",
            "d1ea0f8bb91b47b28537735ec1295760",
            "61fc2c3474404138a60c56efb099b312",
            "00bd676db823477689089dda1d3ed4e5",
            "45d6159bc2e8498ba4fc6ec9a186b6da",
            "534c1c2a9600466383ae155dfc80a69a",
            "84ea1d6643b54b59ad297c0de014384e",
            "bef2c7a21339412fa6d3cbc5fc2dc0f4",
            "bd41be5d2c7d41b198e7d40ffd8e8265",
            "af5c8967257e4d56893e2550aa1f3673",
            "fdb7acfc57f84bea86c8feed75b73b65"
          ]
        },
        "outputId": "67f6c2b2-8d30-44dd-c2ac-554bb028bbbc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q5_K_M.gguf:   0%|          | 0.00/5.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70ab1170a3d14723b8fa2bca67322e29"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lcpp_llm = Llama(\n",
        "        model_path=model_path,\n",
        "        n_threads=200,  # CPU cores\n",
        "        n_batch=100,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "        n_gpu_layers=20,  # Change this value based on your model and your GPU VRAM pool.\n",
        "        n_ctx=4096,  # Context window\n",
        "    )"
      ],
      "metadata": {
        "id": "VaTf7bc_X0jJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb01aae8-1380-4999-d4ce-4383131d80c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q5_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q5_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 20 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 20/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =  4892.99 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  2940.31 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 100\n",
            "llama_new_context_with_model: n_ubatch   = 100\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 1000000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:  CUDA_Host KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   320.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   116.31 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     3.56 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 136\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
            "Guessed chat format: mistral-instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwKq5ThE0Pzg",
        "outputId": "8c3ae86f-9bed-460c-e512-2c6f2b8102d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 23 01:16:35 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              49W / 400W |   3803MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj8Gk-m1Iz1q",
        "tags": []
      },
      "source": [
        "# **Section 2: Text to Label generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MSzOqa_4XwBP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6xcR3o2ga6p",
        "tags": []
      },
      "source": [
        "### **Question 2: Zero-Shot Prompting for Text Classification (5 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ8ual1jghmN",
        "tags": []
      },
      "source": [
        "##### **Q2.1: Define the Prompt Template, System Message, generate_prompt** **(2 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfNlwAXCBVZn"
      },
      "source": [
        "- Define a **system message** as a string and assign it to the variable system_message to generate product class.\n",
        "- Create a **zero shot prompt template** that incorporates the system message and user input.\n",
        "- Define **generate_prompt** function that takes both the system_message and user_input as arguments and formats them into a prompt template\n",
        "\n",
        "\n",
        "Write a Python function called **generate_mistral_response** that takes a single parameter, narrative, which represents the user's complain. Inside the function, you should perform the following tasks:\n",
        "\n",
        "\n",
        "- **Combine the system_message and narrative to create a prompt string using generate_prompt function.**\n",
        "\n",
        "*Generate a response from the Mistral model using the lcpp_llm instance with the following parameters:*\n",
        "\n",
        "- prompt should be the combined prompt string.\n",
        "- max_tokens should be set to 1200.\n",
        "- temperature should be set to 0.\n",
        "- top_p should be set to 0.95.\n",
        "- repeat_penalty should be set to 1.2.\n",
        "- top_k should be set to 50.\n",
        "- stop should be set as a list containing '/s'.\n",
        "- echo should be set to False.\n",
        "Extract and return the response text from the generated response.\n",
        "\n",
        "Don't forget to provide a value for the system_message variable before using it in the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QIMDLp51ghGr"
      },
      "outputs": [],
      "source": [
        "system_message = \"Classify the following customer complaint into categories such as 'Credit Card', 'Bank Account Services', 'Loan', 'Mortgage', and 'Others'. Also, provide a concise summary of the complaint.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e24qaY7ug2CC"
      },
      "outputs": [],
      "source": [
        "zero_shot_prompt_template = \"\"\"<s>[INST] Classify the following customer complaint into categories such as 'Credit Card', 'Bank Account Services', 'Loan', 'Mortgage', and 'Others'. Also, provide a concise summary of the complaint. [/INST]```{user_message}```\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JKOyehERgy77"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(system_message,user_input):\n",
        "    prompt=zero_shot_prompt_template.format(system_message=system_message,user_message=user_input)\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3PJcu3dwg7FO"
      },
      "outputs": [],
      "source": [
        "def generate_mistral_response(input_text):\n",
        "    # log the narrative being processed to monitor progress\n",
        "    print(f'Processing narrative: {input_text[:100]}...')\n",
        "\n",
        "    # Generate a response using the Mistral model\n",
        "    response = lcpp_llm(\n",
        "        prompt=generate_prompt(system_message, input_text),\n",
        "        max_tokens=1200,\n",
        "        temperature=0,\n",
        "        top_p=0.95,\n",
        "        top_k=50,\n",
        "        stop=[\"/s\"],\n",
        "        repeat_penalty=1.2,\n",
        "        echo=False\n",
        "    )\n",
        "\n",
        "    # Extract and return the response text\n",
        "    return response[\"choices\"][0][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvQIKpPHYv3l",
        "outputId": "c5be6b5b-f930-4a61-e5a9-f2f6cc109837"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SpTp2YQjBVZn"
      },
      "outputs": [],
      "source": [
        "# Load a CSV File containing Dataset of 500 products, narrative and summary (summary of narrative)\n",
        "data = pd.read_csv('/content/drive/MyDrive/Generative AI/Complaints_classification.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xhwItJrIhNta"
      },
      "outputs": [],
      "source": [
        "# Randomly select 30 rows\n",
        "new_data = data.sample(n=30, random_state=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-GrdMrVkaei",
        "tags": []
      },
      "source": [
        "##### **Q2.2: Create a new column in the DataFrame called 'mistral_response' and populate it with responses generated by applying the 'generate_mistral_response' function to each 'narrative' in the DataFrame and prepare the mistral_response_cleaned column using extract_category function** **(1 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mistral_response(input_text):\n",
        "    print(\"\\n---Processing new complaint---\")\n",
        "    print(f\"Input: {input_text[:100]}...\")\n",
        "\n",
        "    prompt = generate_prompt(system_message, input_text)\n",
        "    response = lcpp_llm(\n",
        "        prompt=prompt,\n",
        "        max_tokens=1200,\n",
        "        temperature=0,\n",
        "        top_p=0.95,\n",
        "        top_k=50,\n",
        "        stop=[\"/s\"],\n",
        "        repeat_penalty=1.2,\n",
        "        echo=False\n",
        "    )\n",
        "    response_text = response[\"choices\"][0][\"text\"]\n",
        "    print(f\"Response: {response_text}\\n\")\n",
        "    return response_text"
      ],
      "metadata": {
        "id": "0l09ZRkR9Mk9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIZHgob-gW9T",
        "outputId": "311dda87-e980-4556-d5b0-9cec9d7aa338"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 23 01:17:31 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0              49W / 400W |   3803MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJOFHZAbhb6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=4,        # Significantly reduced from 200\n",
        "    n_batch=1,         # Reduced from 100\n",
        "    n_gpu_layers=20,   # Keep this the same\n",
        "    n_ctx=512,        # Significantly reduced from 4096\n",
        ")\n",
        "\n",
        "# Then try an even simpler test\n",
        "test_response = lcpp_llm(\n",
        "    prompt=\"Say hello\",\n",
        "    max_tokens=10,\n",
        "    temperature=0,\n",
        "    echo=False\n",
        ")\n",
        "print(test_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCXYfrG0hbkE",
        "outputId": "8fc17f35-e86d-4408-897e-d75a578a44d6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q5_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q5_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 20 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 20/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =  4892.99 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  2940.31 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 1000000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:  CUDA_Host KV buffer size =    24.00 MiB\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =    40.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   107.45 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.56 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 136\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
            "Guessed chat format: mistral-instruct\n",
            "\n",
            "llama_print_timings:        load time =   10772.41 ms\n",
            "llama_print_timings:      sample time =       5.06 ms /    10 runs   (    0.51 ms per token,  1977.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   11845.97 ms /    13 runs   (  911.23 ms per token,     1.10 tokens per second)\n",
            "llama_print_timings:       total time =   11886.02 ms /    14 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-190dd5ab-ccfe-4ecb-8cda-5fe5d6551a29', 'object': 'text_completion', 'created': 1737595056, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q5_K_M.gguf', 'choices': [{'text': ' to the new and improved version of our popular ', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 4, 'completion_tokens': 10, 'total_tokens': 14}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with just one complaint\n",
        "test_narrative = new_data['narrative'].iloc[0]\n",
        "print(\"Testing classification for:\")\n",
        "print(test_narrative[:100], \"...\\n\")\n",
        "\n",
        "response = lcpp_llm(\n",
        "    prompt=generate_prompt(system_message, test_narrative),\n",
        "    max_tokens=200,  # Reduced from 1200 for testing\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    stop=[\"/s\"],\n",
        "    echo=False\n",
        ")\n",
        "print(\"\\nResponse:\")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy0wU8ZFh8eX",
        "outputId": "28cd799e-5e6d-46cd-8257-26e222edb0c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing classification for:\n",
            "fraudulent charge totaling made capital one checking account via debit card seeing charge immediatel ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   10772.41 ms\n",
            "llama_print_timings:      sample time =      74.45 ms /   124 runs   (    0.60 ms per token,  1665.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   35325.09 ms /   390 runs   (   90.58 ms per token,    11.04 tokens per second)\n",
            "llama_print_timings:       total time =   36333.12 ms /   391 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Response:\n",
            " Based on the provided text, this customer complaint can be classified as 'Bank Account Services' with a sub-category of 'Fraud'. The customer is reporting an unauthorized use of their debit card and disputing a fraudulent charge made to their Capital One checking account. They have been in contact with Capital One multiple times to dispute the charge, but it has not yet been resolved. The customer believes that their debit card was intercepted and fraudulently activated, resulting in unauthorized purchases being made. They have also reported the incident to the local police department's financial services division.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_category(text):\n",
        "    # Define the regex pattern to match \"category:\" or \"Category:\" followed by a word\n",
        "    pattern = r'category:\\s*(\\w+)'  # The pattern itself remains the same\n",
        "\n",
        "    # Use re.search with the re.IGNORECASE flag to make it case-insensitive\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "\n",
        "    # If a match is found, return the captured group, else return None\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        pattern1 = r'(credit_card|retail_banking|credit_reporting|mortgages_and_loans|debt_collection)'\n",
        "        match = re.search(pattern1, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group()\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "def mistral_response_cleaned(text):\n",
        "    # Example of cleaning or extracting information from the text\n",
        "    cleaned_text = text.lower()  # Example transformation\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "y5LSMIPY0WSK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep the current conservative parameters\n",
        "# Reduce to 5 complaints\n",
        "smaller_data = new_data.sample(n=5, random_state=42)\n",
        "\n",
        "# Process one at a time with progress tracking\n",
        "for idx, row in smaller_data.iterrows():\n",
        "    print(f\"\\nProcessing complaint {idx+1}/5\")\n",
        "    try:\n",
        "        response = generate_mistral_response(row['narrative'])\n",
        "        smaller_data.loc[idx, 'mistral_response'] = response\n",
        "        print(f\"Successfully processed complaint {idx+1}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing complaint {idx+1}: {str(e)}\")\n",
        "\n",
        "# Only process cleaned responses for successful ones\n",
        "smaller_data['mistral_response_cleaned'] = smaller_data['mistral_response'].apply(lambda x: mistral_response_cleaned(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEoL_6U0xjmP",
        "outputId": "1d8cf869-37c9-4cb2-eef4-340a830106db"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing complaint 151/5\n",
            "\n",
            "---Processing new complaint---\n",
            "Input: true identity theft victim identity theft information listed appears credit report relate transactio...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   10772.41 ms\n",
            "llama_print_timings:      sample time =     140.30 ms /   232 runs   (    0.60 ms per token,  1653.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   35602.41 ms /   397 runs   (   89.68 ms per token,    11.15 tokens per second)\n",
            "llama_print_timings:       total time =   36851.08 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:  Based on the given customer complaint, it appears that this is a case of Identity Theft. The customer mentions that they are a victim of identity theft and have found fraudulent transactions listed on their Equifax credit report. They also mention that they have been trying to get the issue resolved for some time but have encountered complications in the process.\n",
            "\n",
            "Therefore, this complaint falls under the 'Others' category as it involves issues related to Identity Theft which is not directly linked to Credit Card, Bank Account Services, Loan or Mortgage services. However, since the identity theft has affected their credit report and ability to apply for new credit cards or loans in the future, it could potentially impact these areas as well.\n",
            "\n",
            "The customer expresses frustration with the lengthy and complicated process of resolving the issue and the emotional and financial stress caused by the situation. They have also mentioned that they are seeking legal help and compensation from Equifax for their losses. The customer is asking for assistance in reviewing their credit file carefully to identify any other fraudulent activity and taking remedial steps to rectify the situation.\n",
            "\n",
            "Successfully processed complaint 151\n",
            "\n",
            "Processing complaint 333/5\n",
            "\n",
            "---Processing new complaint---\n",
            "Input: blockexcept otherwise provided section consumer reporting agency shall block reporting information f...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =   10772.41 ms\n",
            "llama_print_timings:      sample time =      12.15 ms /    21 runs   (    0.58 ms per token,  1728.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   40941.36 ms /   455 runs   (   89.98 ms per token,    11.11 tokens per second)\n",
            "llama_print_timings:       total time =   42003.18 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:  This text appears to be a portion of the Consumer Credit Reporting Agencies Act, specifically related to\n",
            "\n",
            "Successfully processed complaint 333\n",
            "\n",
            "Processing complaint 103/5\n",
            "\n",
            "---Processing new complaint---\n",
            "Input: conducted another investigation based new complaint submission able confirm time transaction questio...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =   10772.41 ms\n",
            "llama_print_timings:      sample time =      76.48 ms /   126 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   22987.90 ms /   255 runs   (   90.15 ms per token,    11.09 tokens per second)\n",
            "llama_print_timings:       total time =   23719.96 ms /   256 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: \n",
            "\n",
            "Category: Credit Card\n",
            "\n",
            "Summary: The customer is expressing dissatisfaction with the credit card company's handling of a dispute regarding a transaction on their account. They believe they were wrongly accused of making an unauthorized purchase and are requesting to see proof of this allegation. However, they have been met with resistance from the company and feel disrespected by their communication. The customer also mentions that their credit report has been negatively affected due to the delinquency reporting related to this issue. They want the account closed as soon as possible and are frustrated with the overall experience.\n",
            "\n",
            "Successfully processed complaint 103\n",
            "\n",
            "Processing complaint 57/5\n",
            "\n",
            "---Processing new complaint---\n",
            "Input: american express reduced credit limit without valid justification advance notification spoke rep sta...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =   10772.41 ms\n",
            "llama_print_timings:      sample time =      84.78 ms /   136 runs   (    0.62 ms per token,  1604.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   29430.14 ms /   325 runs   (   90.55 ms per token,    11.04 tokens per second)\n",
            "llama_print_timings:       total time =   30353.59 ms /   326 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: \n",
            "\n",
            "Category: Credit Card\n",
            "\n",
            "Summary: The customer is complaining about American Express reducing their credit limit without prior notification and justification. They believe the decision was made due to an increase in balance on their account, but were later told it was because of their high utilization rate despite always maintaining a good standing account. The customer feels that American Express took advantage of them during a promotional period when they were paying significant amounts towards their balance and is seeking help from financial regulators as they are experiencing financial hardship due to unexpected circumstances such as illness or workplace closure. They also feel that the representative lacked proper training and handling skills, which added to their frustration.\n",
            "\n",
            "Successfully processed complaint 57\n",
            "\n",
            "Processing complaint 239/5\n",
            "\n",
            "---Processing new complaint---\n",
            "Input: block except otherwise provided section consumer reporting agency shall block reporting information ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =   10772.41 ms\n",
            "llama_print_timings:      sample time =      15.54 ms /    27 runs   (    0.58 ms per token,  1737.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   41149.33 ms /   455 runs   (   90.44 ms per token,    11.06 tokens per second)\n",
            "llama_print_timings:       total time =   42244.79 ms /   456 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:  This text appears to be a portion of a statute or regulation related to the blocking and unblocking of consumer credit reports due to\n",
            "\n",
            "Successfully processed complaint 239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K1CBbpD3m_rf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "00ef33d2-2df8-4c2d-805d-7cc4694244bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150     Based on the given customer complaint, it app...\n",
              "332     This text appears to be a portion of the Cons...\n",
              "102    \\n\\nCategory: Credit Card\\n\\nSummary: The cust...\n",
              "56     \\n\\nCategory: Credit Card\\n\\nSummary: The cust...\n",
              "238     This text appears to be a portion of a statut...\n",
              "Name: mistral_response, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mistral_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>Based on the given customer complaint, it app...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>This text appears to be a portion of the Cons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>\\n\\nCategory: Credit Card\\n\\nSummary: The cust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>\\n\\nCategory: Credit Card\\n\\nSummary: The cust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>This text appears to be a portion of a statut...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "smaller_data['mistral_response']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "10Bulypzkwjt"
      },
      "outputs": [],
      "source": [
        "def extract_category(text):\n",
        "    # Define the regex pattern to match \"category:\" or \"Category:\" followed by a word\n",
        "    pattern = r'category:\\s*(\\w+)'  # The pattern itself remains the same\n",
        "\n",
        "    # Use re.search with the re.IGNORECASE flag to make it case-insensitive\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "\n",
        "    # If a match is found, return the captured group, else return None\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        pattern1 = r'(credit_card|retail_banking|credit_reporting|mortgages_and_loans|debt_collection)'\n",
        "        match = re.search(pattern1, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group()\n",
        "        else:\n",
        "            return ''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mistral_response_cleaned(text):\n",
        "    # Example of cleaning or extracting information from the text\n",
        "    cleaned_text = text.lower()  # Example transformation\n",
        "    return cleaned_text\n"
      ],
      "metadata": {
        "id": "pMp3PfsnAJVy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UGfRZ7dUw4tr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "440c2744-c3b4-4954-8d68-6d0cbafc3a8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              product                                          narrative  \\\n",
              "150  credit_reporting  true identity theft victim identity theft info...   \n",
              "332  credit_reporting  blockexcept otherwise provided section consume...   \n",
              "102       credit_card  conducted another investigation based new comp...   \n",
              "56        credit_card  american express reduced credit limit without ...   \n",
              "238  credit_reporting  block except otherwise provided section consum...   \n",
              "\n",
              "                                               summary  \\\n",
              "150  The input discusses an individual who has disc...   \n",
              "332  The text describes regulations on consumer rep...   \n",
              "102  The text indicates an ongoing conflict related...   \n",
              "56   The user has complained about American Express...   \n",
              "238  The section explains the rules and procedures ...   \n",
              "\n",
              "                                      mistral_response  \\\n",
              "150   Based on the given customer complaint, it app...   \n",
              "332   This text appears to be a portion of the Cons...   \n",
              "102  \\n\\nCategory: Credit Card\\n\\nSummary: The cust...   \n",
              "56   \\n\\nCategory: Credit Card\\n\\nSummary: The cust...   \n",
              "238   This text appears to be a portion of a statut...   \n",
              "\n",
              "                              mistral_response_cleaned  \n",
              "150   based on the given customer complaint, it app...  \n",
              "332   this text appears to be a portion of the cons...  \n",
              "102  \\n\\ncategory: credit card\\n\\nsummary: the cust...  \n",
              "56   \\n\\ncategory: credit card\\n\\nsummary: the cust...  \n",
              "238   this text appears to be a portion of a statut...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d7fa316-99a8-41b2-886d-add39c990fef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product</th>\n",
              "      <th>narrative</th>\n",
              "      <th>summary</th>\n",
              "      <th>mistral_response</th>\n",
              "      <th>mistral_response_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>credit_reporting</td>\n",
              "      <td>true identity theft victim identity theft info...</td>\n",
              "      <td>The input discusses an individual who has disc...</td>\n",
              "      <td>Based on the given customer complaint, it app...</td>\n",
              "      <td>based on the given customer complaint, it app...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>credit_reporting</td>\n",
              "      <td>blockexcept otherwise provided section consume...</td>\n",
              "      <td>The text describes regulations on consumer rep...</td>\n",
              "      <td>This text appears to be a portion of the Cons...</td>\n",
              "      <td>this text appears to be a portion of the cons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>credit_card</td>\n",
              "      <td>conducted another investigation based new comp...</td>\n",
              "      <td>The text indicates an ongoing conflict related...</td>\n",
              "      <td>\\n\\nCategory: Credit Card\\n\\nSummary: The cust...</td>\n",
              "      <td>\\n\\ncategory: credit card\\n\\nsummary: the cust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>credit_card</td>\n",
              "      <td>american express reduced credit limit without ...</td>\n",
              "      <td>The user has complained about American Express...</td>\n",
              "      <td>\\n\\nCategory: Credit Card\\n\\nSummary: The cust...</td>\n",
              "      <td>\\n\\ncategory: credit card\\n\\nsummary: the cust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>credit_reporting</td>\n",
              "      <td>block except otherwise provided section consum...</td>\n",
              "      <td>The section explains the rules and procedures ...</td>\n",
              "      <td>This text appears to be a portion of a statut...</td>\n",
              "      <td>this text appears to be a portion of a statut...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d7fa316-99a8-41b2-886d-add39c990fef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d7fa316-99a8-41b2-886d-add39c990fef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d7fa316-99a8-41b2-886d-add39c990fef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34c8b86a-1ea5-4b62-bdf8-7d88cda2d6d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34c8b86a-1ea5-4b62-bdf8-7d88cda2d6d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34c8b86a-1ea5-4b62-bdf8-7d88cda2d6d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "smaller_data",
              "summary": "{\n  \"name\": \"smaller_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"product\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"credit_card\",\n          \"credit_reporting\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"narrative\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"blockexcept otherwise provided section consumer reporting agency shall block reporting information file consumer consumer identifies information resulted alleged identity theft later business day date receipt agenc appropriate proof identity consumer copy identity theft report identification information consumer statement consumer information information relating transaction consumer b notificationa consumer reporting agency shall promptly notify furnisher information identified consumer subsection information may result identity theft identity theft report filed block requested section effective date block c authority decline rescind generala consumer reporting agency may decline block may rescind block information relating consumer section consumer reporting agency reasonably determines information blocked error block requested consumer error b information blocked block requested consumer basis material misrepresentation fact consumer relevant request block c consumer obtained possession good service money result blocked transaction transaction notification consumer block information declined rescinded subsection affected consumer shall notified promptly manner consumer notified reinsertion information section b title significance block purpose subsection consumer reporting agency rescinds block presence information file consumer prior blocking information evidence whether consumer knew known consumer obtained possession good service money result block exception resellers reseller filethis section shall apply consumer reporting agency consumerreporting agency reseller b time request consumer subsection otherwise furnishing reselling consumer report concerning information identified consumer c informs consumer mean consumer may report identity theft bureau obtain consumer information regarding identity theft reseller filethe sole obligation consumer reporting agency section regard request consumer section shall block consumer report maintained consumer reporting agency subsequent use consumer accordance provision subsection identifies consumerreporting agency information file consumer resulted identity theft b consumer reporting agency reseller identified information notice carrying obligation paragraph reseller shall promptly provide notice consumer decision block file notice shall contain name address telephone number consumer reporting agency consumer information obtained resale e exception verification company provision section apply check service company acting issue authorization purpose approving processing negotiable instrument electronic fund transfer similar method payment except beginning business day receipt information described paragraph subsection check service company shall report national consumer reporting agency described section p title information identified subject identity theft report resulting identity theft f access blocked information law enforcement agency provision section shall construed requiring consumer reporting agency prevent federal state local law enforcement agency accessing blocked information consumer file agency could otherwise obtain access subchapter\",\n          \"block except otherwise provided section consumer reporting agency shall block reporting information file consumer consumer identifies information resulted alleged identity theft later business day date receipt agency appropriate proof identity consumer copy identity theft report identification information consumer statement consumer information information relating transaction consumer b notification consumer reporting agency shall promptly notify furnisher information identified consumer subsection section information may result identity theft identity theft report filed block requested section effective date block c authority decline rescind general consumer reporting agency may decline block may rescind block information relating consumer section consumer reporting agency reasonably determines information blocked error block requested consumer error b information blocked block requested consumer basis material misrepresentation fact consumer relevant request block c consumer obtained possession good service money result blocked transaction transaction notification consumer block information declined rescinded subsection affected consumer shall notified promptly manner consumer notified reinsertion information section b title significance block purpose subsection consumer reporting agency rescinds block presence information file consumer prior blocking information evidence whether consumer knew known consumer obtained possession good service money result block exception resellers reseller file section shall apply consumer reporting agency consumer reporting agency reseller b time request consumer subsection section otherwise furnishing reselling consumer report concerning information identified consumer c informs consumer mean consumer may report identity theft bureau obtain consumer information regarding identity theft reseller file sole obligation consumer reporting agency section regard request consumer section shall block consumer report maintained consumer reporting agency subsequent use consumer accordance provision subsection section identifies consumer reporting agency information file consumer resulted identity theft b consumer reporting agency reseller identified information notice carrying obligation paragraph reseller shall promptly provide notice consumer decision block file notice shall contain name address telephone number consumer reporting agency consumer information obtained resale e exception verification company provision section apply check service company acting issue authorization purpose approving processing negotiable instrument electronic fund transfer similar method payment except beginning business day receipt information described paragraph subsection section check service company shall report national consumer reporting agency described section p title information identified subject identity theft report resulting identity theft f access blocked information law enforcement agency provision section shall construed requiring consumer reporting agency prevent federal state local law enforcement agency accessing blocked information consumer file agency could otherwise obtain access subchapter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The text describes regulations on consumer reporting agencies regarding blocking and reporting of information in cases of alleged identity theft. The consumer can request a block on any information they identify as stemming from identity theft and provide relevant proof. The reporting agency is obliged to block the information and notify the furnisher. However, the agency can decline or rescind the block in case of errors or misrepresentations, and should promptly inform the consumer in such cases.\\n\\nThe text also highlights the obligations and exceptions of resellers and verification companies. Resellers need to block the information upon request and inform the consumer of any official source where they can report identity theft. Verification companies involved in authorizing payments are exempted, but they still need to report any suspected identity theft to national consumer reporting agencies.\\n\\nThe text states that law enforcement agencies can access blocked information if necessary, assuming they could access it under normal circumstances.\",\n          \"The section explains the rules and procedures for blocking information related to identity theft reports in consumer files. It allows consumer reporting agencies to block the reporting of inauthentic data identified by the user. The agency should then notify the provider of that information about potential identity fraud. However, agencies can decline or rescind a block if they determine it was made in error or based on a material misrepresentation of facts. In case a block is declined or rescinded, the consumer will be notified promptly. The section also instructs resellers on how to manage information related to identity theft. It exempts check service companies from these regulations, but it requires that they report any identified identity theft information to national consumer reporting agencies immediately upon receipt. This section does not restrict law enforcement agencies' access to blocked information in consumer files.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mistral_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \" This text appears to be a portion of the Consumer Credit Reporting Agencies Act, specifically related to\",\n          \" This text appears to be a portion of a statute or regulation related to the blocking and unblocking of consumer credit reports due to\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mistral_response_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \" this text appears to be a portion of the consumer credit reporting agencies act, specifically related to\",\n          \" this text appears to be a portion of a statute or regulation related to the blocking and unblocking of consumer credit reports due to\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "smaller_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nExample comparison:\")\n",
        "print(\"\\nOriginal response:\")\n",
        "print(smaller_data['mistral_response'].iloc[0])\n",
        "print(\"\\nCleaned response:\")\n",
        "print(smaller_data['mistral_response_cleaned'].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0VzdUOv8eFw",
        "outputId": "33f0ed92-10e8-40ac-eed3-b14cfb45a986"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example comparison:\n",
            "\n",
            "Original response:\n",
            " Based on the given customer complaint, it appears that this is a case of Identity Theft. The customer mentions that they are a victim of identity theft and have found fraudulent transactions listed on their Equifax credit report. They also mention that they have been trying to get the issue resolved for some time but have encountered complications in the process.\n",
            "\n",
            "Therefore, this complaint falls under the 'Others' category as it involves issues related to Identity Theft which is not directly linked to Credit Card, Bank Account Services, Loan or Mortgage services. However, since the identity theft has affected their credit report and ability to apply for new credit cards or loans in the future, it could potentially impact these areas as well.\n",
            "\n",
            "The customer expresses frustration with the lengthy and complicated process of resolving the issue and the emotional and financial stress caused by the situation. They have also mentioned that they are seeking legal help and compensation from Equifax for their losses. The customer is asking for assistance in reviewing their credit file carefully to identify any other fraudulent activity and taking remedial steps to rectify the situation.\n",
            "\n",
            "Cleaned response:\n",
            " based on the given customer complaint, it appears that this is a case of identity theft. the customer mentions that they are a victim of identity theft and have found fraudulent transactions listed on their equifax credit report. they also mention that they have been trying to get the issue resolved for some time but have encountered complications in the process.\n",
            "\n",
            "therefore, this complaint falls under the 'others' category as it involves issues related to identity theft which is not directly linked to credit card, bank account services, loan or mortgage services. however, since the identity theft has affected their credit report and ability to apply for new credit cards or loans in the future, it could potentially impact these areas as well.\n",
            "\n",
            "the customer expresses frustration with the lengthy and complicated process of resolving the issue and the emotional and financial stress caused by the situation. they have also mentioned that they are seeking legal help and compensation from equifax for their losses. the customer is asking for assistance in reviewing their credit file carefully to identify any other fraudulent activity and taking remedial steps to rectify the situation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9t6gsZVsL2b",
        "tags": []
      },
      "source": [
        "##### **Q2.3: Calculate the F1 score** **(1 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's print each row's values to see what we're comparing\n",
        "for idx, row in smaller_data.iterrows():\n",
        "    print(\"\\nRow\", idx)\n",
        "    print(\"Product (actual):\", row['product'])\n",
        "    print(\"Response (predicted):\", row['mistral_response'][:100], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMEARIVH9dBJ",
        "outputId": "edb80b7b-56ca-4ff4-f8a3-3998037d662a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row 150\n",
            "Product (actual): credit_reporting\n",
            "Response (predicted):  Based on the given customer complaint, it appears that this is a case of Identity Theft. The custom ...\n",
            "\n",
            "Row 332\n",
            "Product (actual): credit_reporting\n",
            "Response (predicted):  This text appears to be a portion of the Consumer Credit Reporting Agencies Act, specifically relat ...\n",
            "\n",
            "Row 102\n",
            "Product (actual): credit_card\n",
            "Response (predicted): \n",
            "\n",
            "Category: Credit Card\n",
            "\n",
            "Summary: The customer is expressing dissatisfaction with the credit card co ...\n",
            "\n",
            "Row 56\n",
            "Product (actual): credit_card\n",
            "Response (predicted): \n",
            "\n",
            "Category: Credit Card\n",
            "\n",
            "Summary: The customer is complaining about American Express reducing their  ...\n",
            "\n",
            "Row 238\n",
            "Product (actual): credit_reporting\n",
            "Response (predicted):  This text appears to be a portion of a statute or regulation related to the blocking and unblocking ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test category extraction on our responses\n",
        "for idx, row in smaller_data.iterrows():\n",
        "    extracted = extract_category(row['mistral_response'])\n",
        "    print(\"\\nRow\", idx)\n",
        "    print(\"Original product:\", row['product'])\n",
        "    print(\"Extracted category:\", extracted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hopv8iKJ9k5d",
        "outputId": "b3162717-1f16-496c-c215-f3f173ecf104"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row 150\n",
            "Original product: credit_reporting\n",
            "Extracted category: \n",
            "\n",
            "Row 332\n",
            "Original product: credit_reporting\n",
            "Extracted category: \n",
            "\n",
            "Row 102\n",
            "Original product: credit_card\n",
            "Extracted category: Credit\n",
            "\n",
            "Row 56\n",
            "Original product: credit_card\n",
            "Extracted category: Credit\n",
            "\n",
            "Row 238\n",
            "Original product: credit_reporting\n",
            "Extracted category: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_category(text):\n",
        "    # First try to match 'Category: X' pattern\n",
        "    pattern = r'Category:\\s*([\\w\\s]+)'\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "\n",
        "    if match:\n",
        "        category = match.group(1).strip().lower()\n",
        "        # Map extracted category to standard format\n",
        "        if 'credit card' in category:\n",
        "            return 'credit_card'\n",
        "        if 'bank' in category:\n",
        "            return 'retail_banking'\n",
        "        if 'credit report' in category:\n",
        "            return 'credit_reporting'\n",
        "        if 'mortgage' in category:\n",
        "            return 'mortgages_and_loans'\n",
        "        if 'debt' in category:\n",
        "            return 'debt_collection'\n",
        "\n",
        "    # If no category label, try to 'infer' from content\n",
        "    text = text.lower()\n",
        "    if 'credit card' in text:\n",
        "        return 'credit_card'\n",
        "    if 'credit report' in text or 'credit reporting' in text:\n",
        "        return 'credit_reporting'\n",
        "    if 'mortgage' in text:\n",
        "        return 'mortgages_and_loans'\n",
        "    if 'debt' in text:\n",
        "        return 'debt_collection'\n",
        "    if 'bank' in text:\n",
        "        return 'retail_banking'\n",
        "\n",
        "    return ''  # Return empty string if no category found"
      ],
      "metadata": {
        "id": "snhx8SD8-Lut"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smaller_data['extracted_categories'] = smaller_data['mistral_response'].apply(lambda x: extract_category(x))"
      ],
      "metadata": {
        "id": "uKk6NLRY-U6p"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(smaller_data['product'], smaller_data['extracted_categories'], average='micro')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIK8zPrU-WHU",
        "outputId": "ab9e8d9b-7a25-4d51-b17e-c5059d03ae9e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CeUoZb4ttDCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d0ad20-80be-4084-97e6-27779058a196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Calculate F1 score for 'product' and 'mistral_response'\n",
        "f1 =  f1_score(smaller_data['product'], smaller_data['mistral_response'],average='micro')\n",
        "\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate F1 score for 'product' and raw mistral_response\n",
        "f1_raw = f1_score(smaller_data['product'],\n",
        "                  smaller_data['mistral_response'].apply(lambda x: extract_category(x)),\n",
        "                  average='micro')\n",
        "\n",
        "# Calculate F1 score for 'product' and cleaned mistral_response\n",
        "f1_cleaned = f1_score(smaller_data['product'],\n",
        "                      smaller_data['mistral_response_cleaned'].apply(lambda x: extract_category(x)),\n",
        "                      average='micro')\n",
        "\n",
        "print(f'F1 Score (Raw Response): {f1_raw}')\n",
        "print(f'F1 Score (Cleaned Response): {f1_cleaned}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLF5kCuxd1tg",
        "outputId": "7e2b5e4f-4bf4-4ca3-e1c3-a69e68ae4952"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (Raw Response): 0.8\n",
            "F1 Score (Cleaned Response): 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ynzQvTi8tCcp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "b62058d9-ec16-4470-ce85-0702a5e6b415"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 2) (<ipython-input-57-b63fc6e4ba81>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-b63fc6e4ba81>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    f2 =  f1_score(\"product, \"mistral_response_cleaned\", average='micro')\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
          ]
        }
      ],
      "source": [
        "# Calculate F1 score for 'product' and 'mistral_response_cleaned'\n",
        "f2 =  f1_score(\"product, \"mistral_response_cleaned\", average='micro')\n",
        "print(f'F1 Score: {f2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MiPbNlwhhw7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0eex3dfGhw87"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "803ZuG7OtSSj",
        "tags": []
      },
      "source": [
        "##### **Q2.4: Explain the difference in F1 scores between mistral_response and mistral_response_cleaned.** **(1 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the zero-shot text classification approach, I investigated the impact of text cleaning specifically, on category extraction by implementing two strategies.\n",
        "\n",
        "* A basic lowercase conversion\n",
        "* A more comprehensive cleaning method involving 'special' character removal and word filtering.\n",
        "\n",
        "Both cleaning approaches yielded an identical F1 score of 0.8\n",
        "The category extraction method demonstrated consistent performance across different cleaning techniques.\n",
        "\n",
        "A few key insights include:\n",
        "\n",
        "Simple lowercase conversion was just as effective as the more complex cleaning method.\n",
        "Category extraction depends on 'meaningful' keyword associations rather than extensive text formatting.\n",
        "Mistrals zero-shot classification model showed robust performance with minimal preprocessing  however, numerous challenges emerged managing the parameters compute performance which appeared to be lagging. Attempts to process the data in smaller batches and demonstrating a proof of concept with a single test while promising, leave a large space for improvement through trial and error, perhaps using quantization techniques to enhance the model.\n",
        "\n",
        "The use of minimalized text prerocessing (lowercase conversion) enabled  the text to perform accurate, categorical extraction demonstrating the Mistral model can effectively, identify categories only requiring, minimal cleaning.\n"
      ],
      "metadata": {
        "id": "-cvzoqZJh6nq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5znlDvcggYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0YUCSXAnx3y",
        "tags": []
      },
      "source": [
        "### **Question 3: Few-Shot Prompting for Text Classification (7 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgxdRjW_wHId",
        "tags": []
      },
      "source": [
        "##### **Q3.1: Prepare examples for a few-shot prompt, formulate the prompt, and generate the Mistral response. (5 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPuH7_ravBtS"
      },
      "source": [
        "**Generate a set of gold examples by randomly selecting 10 instances of user_input and assistant_output from dataset ensuring a balanced representation with 2 examples from each class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "iO9Wj19_n_LO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a67f68-945d-4e71-a41f-4c089a8fca17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'narrative': 'called request new york state covid relief plan day interest fee waived amex provided relief leading late payment amex refused honor relief day gap insists charging late fee', 'product': 'credit_card'}\n",
            "Examples Set Shape: (10, 3)\n",
            "Gold Examples Shape: (490, 3)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "review_1 = data[data['product'] == 'credit_card']\n",
        "review_2 = data[data['product'] == 'retail_banking']\n",
        "review_3 = data[data['product'] == 'credit_reporting']\n",
        "review_4 = data[data['product'] == 'mortgages_and_loans']\n",
        "review_5 = data[data['product'] == 'debt_collection']\n",
        "\n",
        "# Sample 2 examples for each category\n",
        "examples_1 = review_1.sample(2, random_state=40)\n",
        "examples_2 = review_2.sample(2, random_state=40)\n",
        "examples_3 = review_3.sample(2, random_state=40)\n",
        "examples_4 = review_4.sample(2, random_state=40)\n",
        "examples_5 = review_5.sample(2, random_state=40)\n",
        "\n",
        "# Concatenate examples for few shot prompting\n",
        "examples_df = pd.concat([examples_1,examples_2,examples_3,examples_4,examples_5 ])\n",
        "\n",
        "# Create the training set by excluding examples\n",
        "gold_examples_df = data.drop(index=examples_df.index)\n",
        "\n",
        "# Convert examples to JSON\n",
        "columns_to_select = ['narrative', 'product']\n",
        "examples_json = examples_df[columns_to_select].to_json(orient='records')\n",
        "\n",
        "# Print the first record from the JSON\n",
        "print(json.loads(examples_json)[0])\n",
        "\n",
        "# Print the shapes of the datasets\n",
        "print(\"Examples Set Shape:\", examples_df.shape)\n",
        "print(\"Gold Examples Shape:\", gold_examples_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8taCkTwqOl"
      },
      "source": [
        "- Define your **system_message**.\n",
        "- Define **first_turn_template**, **example_template** and **prediction template**\n",
        "- **create few shot prompt** using gold examples and system_message\n",
        "- Randomly select 30 rows from test_df as test_data\n",
        "- Create **mistral_response** with **mistral_response_cleaned** columns for this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iPzpBeWmzSIH"
      },
      "outputs": [],
      "source": [
        "system_message = system_message = \"You are an expert at classifying customer complaints into specific financial product categories. Use the following examples to understand the classification patterns and accurately categorize new customer complaints into one of these categories: 'Credit Card', 'Bank Account Services', 'Loan', 'Mortgage', and 'Others'.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XRIN9SB80fK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Template for few-shot learning\n",
        "first_turn_template = \"\"\"<s>[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>```{user_message}``` [/INST]\n",
        "{assistant_message}\n",
        "</s>\"\"\"\n",
        "\n",
        "examples_template = \"\"\"<s>[INST] ```{user_message}``` [/INST]\n",
        "{assistant_message}\n",
        "</s>\"\"\"\n",
        "\n",
        "prediction_template = \"\"\"<s>[INST] ```{user_message}``` [/INST]\"\"\"\n",
        "\n",
        "def generate_prompt(few_shot_prompt, new_review):\n",
        "    prompt = few_shot_prompt + prediction_template.format(user_message=new_review)\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "jM2yzBXK0fJq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "X07_kNji0vTp"
      },
      "outputs": [],
      "source": [
        "def create_few_shot_prompt(system_message, examples_df):\n",
        "\n",
        "    \"\"\"\n",
        "    Return a prompt message in the format expected by Mistral 7b.\n",
        "    10 examples are selected randomly as golden examples to form the\n",
        "    few-shot prompt.\n",
        "    We then loop through each example and parse the narrative as the user message\n",
        "    and the product as the assistant message.\n",
        "\n",
        "    Args:\n",
        "        system_message (str): system message with instructions for classification\n",
        "        examples(DataFrame): A DataFrame with examples (product + narrative + summary)\n",
        "        to form the few-shot prompt.\n",
        "\n",
        "    Output:\n",
        "        few_shot_prompt (str): A prompt string in the Mistral format\n",
        "    \"\"\"\n",
        "\n",
        "    few_shot_prompt = ''\n",
        "\n",
        "    columns_to_select = ['narrative', 'product']\n",
        "    examples = (\n",
        "        examples_df.loc[:, columns_to_select].to_json(orient='records')\n",
        "    )\n",
        "\n",
        "    for idx, example in enumerate(json.loads(examples)):\n",
        "        user_input_example = example['narrative']\n",
        "        assistant_output_example = example['product']\n",
        "\n",
        "        if idx == 0:\n",
        "            few_shot_prompt += first_turn_template.format(\n",
        "                system_message=system_message,\n",
        "                user_input=user_input_example,\n",
        "                assistant_output=assistant_output_example\n",
        "            )\n",
        "        else:\n",
        "            few_shot_prompt += examples_template.format(\n",
        "                user_input=user_input_example,\n",
        "                assistant_output=assistant_output_example\n",
        "            )\n",
        "\n",
        "    return few_shot_prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"<s>[INST] <<SYS>>\n",
        "You are an expert at classifying customer complaints into specific financial product categories. Use the following examples to understand the classification patterns and accurately categorize new customer complaints into one of these categories: 'Credit Card', 'Bank Account Services', 'Loan', 'Mortgage', and 'Others'.\n",
        "<</SYS>>\n",
        "\n",
        "Examples:\n",
        "1. User: \"My credit card was charged twice for a single transaction and the bank is not resolving it.\"\n",
        "Assistant: credit_card\n",
        "\n",
        "2. User: \"My checking account was frozen without any notice and I can't access my funds.\"\n",
        "Assistant: retail_banking\n",
        "\n",
        "3. User: \"There are errors in my credit report that I've disputed multiple times.\"\n",
        "Assistant: credit_reporting\n",
        "\n",
        "4. User: \"The mortgage company increased my monthly payments without proper explanation.\"\n",
        "Assistant: mortgages_and_loans\n",
        "\n",
        "5. User: \"Collection agency keeps calling about a debt I've already paid off.\"\n",
        "Assistant: debt_collection[/INST]\"\"\""
      ],
      "metadata": {
        "id": "onQllw_uqPQO"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "uPsvRQrC0Afr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67681f48-2e48-4066-e3bb-5ecc7dcf1435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] <<SYS>>\n",
            "You are an expert at classifying customer complaints into specific financial product categories. Use the following examples to understand the classification patterns and accurately categorize new customer complaints into one of these categories: 'Credit Card', 'Bank Account Services', 'Loan', 'Mortgage', and 'Others'.\n",
            "<</SYS>>\n",
            "\n",
            "Examples:\n",
            "1. User: \"My credit card was charged twice for a single transaction and the bank is not resolving it.\"\n",
            "Assistant: credit_card\n",
            "\n",
            "2. User: \"My checking account was frozen without any notice and I can't access my funds.\" \n",
            "Assistant: retail_banking\n",
            "\n",
            "3. User: \"There are errors in my credit report that I've disputed multiple times.\"\n",
            "Assistant: credit_reporting\n",
            "\n",
            "4. User: \"The mortgage company increased my monthly payments without proper explanation.\"\n",
            "Assistant: mortgages_and_loans\n",
            "\n",
            "5. User: \"Collection agency keeps calling about a debt I've already paid off.\"\n",
            "Assistant: debt_collection[/INST]\n"
          ]
        }
      ],
      "source": [
        "print(few_shot_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(few_shot_prompt, new_review):\n",
        "    prompt = few_shot_prompt + prediction_template.format(user_message=new_review)\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "aYL_vr041TtQ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "GKrndCFRCJhK"
      },
      "outputs": [],
      "source": [
        "def generate_mistral_response(input_text):\n",
        "    prompt = generate_prompt(few_shot_prompt, input_text)\n",
        "    response = lcpp_llm(\n",
        "        prompt=prompt,\n",
        "        max_tokens=1200,\n",
        "        temperature=0,\n",
        "        top_p=0.95,\n",
        "        repeat_penalty=1.2,\n",
        "        top_k=50,\n",
        "        stop=[\"/s\"],\n",
        "        echo=False\n",
        "    )\n",
        "\n",
        "    return response[\"choices\"][0][\"text\"]\n",
        "\n",
        "    # Extract and return the response text\n",
        "    response_text = response[\"choices\"][0][\"text\"]\n",
        "    print(response_text)\n",
        "    return response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "FKYOjm7LDLJj"
      },
      "outputs": [],
      "source": [
        "# Randomly select 50 rows from gold_examples\n",
        "\n",
        "#1 Create the training set by excluding examples used for few-shot prompting\n",
        "gold_examples_df = data.drop(index=examples_df.index)\n",
        "\n",
        "#2 Randomly select 50 rows from remaining data\n",
        "new_data = gold_examples_df.sample(n=50, random_state=40)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinitalize the model with larger context window\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=4,\n",
        "    n_batch=32,\n",
        "    n_gpu_layers=20,\n",
        "    n_ctx=2048  # Increase context window\n",
        ")\n",
        "\n",
        "# Test with 'one' complaint to make sure it works\n",
        "test_narrative = new_data['narrative'].iloc[0]\n",
        "print(\"Testing with narrative:\", test_narrative[:100], \"...\")\n",
        "\n",
        "test_response = generate_mistral_response(test_narrative)\n",
        "print(\"\\nResponse:\", test_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbLUEEfz2Y_A",
        "outputId": "9046f1f4-89c3-4ed8-867b-37a6cee01aed"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q5_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q5_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 20 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 20/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =  4892.99 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  2940.31 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 1000000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:  CUDA_Host KV buffer size =    96.00 MiB\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   160.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   106.95 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.75 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 136\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
            "Guessed chat format: mistral-instruct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with narrative: anyone us credit report another consumer report deny credit must tell give name address phone number ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     596.64 ms /   991 runs   (    0.60 ms per token,  1660.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =   16712.56 ms /   901 tokens (   18.55 ms per token,    53.91 tokens per second)\n",
            "llama_print_timings:        eval time =   93794.60 ms /   990 runs   (   94.74 ms per token,    10.55 tokens per second)\n",
            "llama_print_timings:       total time =  114912.89 ms /  1891 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Response:  Based on the provided text, it appears that there are multiple complaints mentioned in this conversation. Here's how I would categorize each complaint based on the context:\n",
            "\n",
            "1. Credit Card: \"My credit card was charged twice for a single transaction and the bank is not resolving it.\" - This complaint falls under the category of credit cards as it specifically mentions a credit card being charged twice without authorization, which is a common issue related to credit card transactions.\n",
            "2. Bank Account Services (Retail Banking): \"My checking account was frozen without any notice and I can't access my funds.\" - This complaint falls under the category of retail banking as it mentions a checking account being frozen without prior notification, which is an issue that typically relates to bank account services or customer service.\n",
            "3. Credit Report: \"There are errors in my credit report that I've disputed multiple times\" and \"feel still fraudulent activity score cleared identity theft identity fraud locked account unable see credit score individual illegally using credit data account criminal activity personal profit must held accountable fraud fraudulent activity debt always pay bill rent time obviously get credit card supplemental security income nc able account allows pay save qualified expense housing transportation expense victim fraud ever allow individual continue illegal business practice recently complaint discrimination suit summit funding nmls assistant provided thorough original document needed complete fha k loan rehabilitation federal housing urban development program fha program person low low income summit funding inc state equal lending agency case first never returned call took week already work buying house help revitalization program federal law mistreating people financial circumstance different based equal fair lending practice follow law business practice make official determination loan approved work loan officiers talking abruptly rushed phone already explained concern proof credit worthiness requirement go fha k loan first time home buyer said use use credit requirement changed due co vid let know case loan fha k based equal fair lending ethical practice credit check non conventional based ssi recipient even tell credit score went say fha loan explained fha k fha completely different said credit requirement changed legal reason laughed said credit union nc maybe layover credit union layover credit check said get premier credit card obviously lack knowledge experience legality equal fair housing business practice ignorant type people different circumstance even apply credit card low income ssi defeat purpose hypocrisy whole point main reason hud program made person lender supposed loan officiers running illegal scam scandal using fraud following job duty equal fair housing federal state law unfortunately deal individual want quick pay check want deal easy follow law according specific loan serve want borrowed time malpractice go whole establishment fha k put loan person unfair unethical business practice called real estate malpractice must report file complaint suit even though still good employee hard working american every field every industry always degenerate think scheme whatever way wo follow set rule guideline even law govern protect people degenerate completion help way waste time waste company work summit funding inc filling discrimination suit need credit score checked credit file sent debt account feel since case credit report ordered paid well someone fraudulently changed credit score right get accurate score\" - This complaint falls under the category of credit reporting as it mentions errors on a credit report and identity theft, which are common issues related to credit reports. However, there are also several other complaints mentioned in this text that do not directly relate to credit cards or credit reports but rather involve banking services (retail banking), loans, mortgages, and discrimination suits. These additional complaints should be categorized accordingly based on the specific details provided for each complaint.\n",
            "4. Loan: \"The mortgage company increased my monthly payments without proper explanation.\" - This complaint falls under the category of loans as it mentions an increase in monthly mortgage payments without a clear explanation from the mortgage company, which is a common issue related to loan repayment plans and terms.\n",
            "5. Mortgage: \"Collection agency keeps calling about a debt I've already paid off.\" - This complaint falls under the category of mortgages as it mentions a collection agency contacting someone regarding a debt that has allegedly been paid off, which is an issue related to mortgage payments or loan repayment plans.\n",
            "6. Others: The remaining complaints in the text do not fit neatly into any of the given categories and may require further investigation to determine their specific category. For example, some complaints mention issues with a credit union, layover credit checks, discrimination suits, and equal fair lending practices. These issues could potentially fall under various categories depending on the specific details provided for each complaint.\n",
            "\n",
            "In summary, based on the context of each complaint as presented in the text, I would categorize the first two complaints as \"Credit Card\" and \"Retail Banking,\" respectively. The remaining complaints may require further investigation to determine their specific category.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with short input\n",
        "test_text = \"This is a credit card dispute.\"\n",
        "response = lcpp_llm(\n",
        "    prompt=test_text,\n",
        "    max_tokens=50,  # Much smaller output\n",
        "    temperature=0,\n",
        "    echo=False\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51ZvXmKS2Y7l",
        "outputId": "1b77f284-887e-40ef-9e14-9aed1d931da4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      26.82 ms /    50 runs   (    0.54 ms per token,  1863.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.10 ms /     7 tokens (   37.59 ms per token,    26.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4398.11 ms /    49 runs   (   89.76 ms per token,    11.14 tokens per second)\n",
            "llama_print_timings:       total time =    4836.36 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-1a18912b-81ce-48ff-8b5f-b5f7dc31999d', 'object': 'text_completion', 'created': 1737597195, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q5_K_M.gguf', 'choices': [{'text': ' I made a purchase on Amazon using my Capital One Venture Rewards Card on 12/30/2018 for $54.99. The item was delivered on 1/1/2019', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 8, 'completion_tokens': 50, 'total_tokens': 58}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example - new_data['mistral_response_cleaned'] = new_data['narrative'].apply(lambda x:______ )\n",
        "new_data['mistral_response'] = new_data['narrative'].apply(lambda x: generate_mistral_response(x))"
      ],
      "metadata": {
        "id": "6jSMNshH4Wwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the response column\n",
        "new_data['mistral_response'] = None\n",
        "\n",
        "# Process in small batches with progress tracking / indexing\n",
        "batch_size = 5\n",
        "total_rows = len(new_data)\n",
        "total_batches = (total_rows + batch_size - 1) // batch_size\n",
        "responses = []\n",
        "\n",
        "for start_idx in range(0, total_rows, batch_size):\n",
        "    print(f\"\\nProcessing batch {start_idx//batch_size + 1} of {total_batches}\")\n",
        "\n",
        "    # Get the end index for this batch\n",
        "    end_idx = min(start_idx + batch_size, total_rows)\n",
        "    batch = new_data.iloc[start_idx:end_idx]\n",
        "\n",
        "    batch_responses = []\n",
        "    for _, row in batch.iterrows():\n",
        "        print(f\"Processing complaint...\")\n",
        "        try:\n",
        "            truncated_text = row['narrative'][:500]\n",
        "            response = lcpp_llm(\n",
        "                prompt=truncated_text,\n",
        "                max_tokens=200,\n",
        "                temperature=0,\n",
        "                echo=False\n",
        "            )\n",
        "            batch_responses.append(response[\"choices\"][0][\"text\"])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing complaint: {e}\")\n",
        "            batch_responses.append(None)\n",
        "\n",
        "    # Update the dataframe directly for this batch\n",
        "    for i, response in enumerate(batch_responses):\n",
        "        new_data.iloc[start_idx + i, new_data.columns.get_loc('mistral_response')] = response\n",
        "\n",
        "    print(f\"Completed batch {start_idx//batch_size + 1}\")\n",
        "\n",
        "print(\"\\nProcessing complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It-Qqdup9zC7",
        "outputId": "c9f81cf3-3e6c-4214-d035-4b619c88c627"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing batch 1 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     119.47 ms /   200 runs   (    0.60 ms per token,  1674.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1837.59 ms /    89 tokens (   20.65 ms per token,    48.43 tokens per second)\n",
            "llama_print_timings:        eval time =   17993.96 ms /   199 runs   (   90.42 ms per token,    11.06 tokens per second)\n",
            "llama_print_timings:       total time =   20604.58 ms /   288 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     112.00 ms /   200 runs   (    0.56 ms per token,  1785.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1597.29 ms /    63 tokens (   25.35 ms per token,    39.44 tokens per second)\n",
            "llama_print_timings:        eval time =   17937.70 ms /   199 runs   (   90.14 ms per token,    11.09 tokens per second)\n",
            "llama_print_timings:       total time =   20295.44 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     118.18 ms /   200 runs   (    0.59 ms per token,  1692.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1396.83 ms /    11 tokens (  126.98 ms per token,     7.87 tokens per second)\n",
            "llama_print_timings:        eval time =   17806.56 ms /   199 runs   (   89.48 ms per token,    11.18 tokens per second)\n",
            "llama_print_timings:       total time =   19954.57 ms /   210 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.83 ms /   200 runs   (    0.42 ms per token,  2357.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1591.31 ms /    63 tokens (   25.26 ms per token,    39.59 tokens per second)\n",
            "llama_print_timings:        eval time =   17829.87 ms /   199 runs   (   89.60 ms per token,    11.16 tokens per second)\n",
            "llama_print_timings:       total time =   20138.34 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.51 ms /   200 runs   (    0.56 ms per token,  1793.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1575.16 ms /    63 tokens (   25.00 ms per token,    40.00 tokens per second)\n",
            "llama_print_timings:        eval time =   17835.23 ms /   199 runs   (   89.62 ms per token,    11.16 tokens per second)\n",
            "llama_print_timings:       total time =   20163.12 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 1\n",
            "\n",
            "Processing batch 2 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.68 ms /   200 runs   (    0.56 ms per token,  1790.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   17948.97 ms /   200 runs   (   89.74 ms per token,    11.14 tokens per second)\n",
            "llama_print_timings:       total time =   18695.96 ms /   201 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.70 ms /   200 runs   (    0.42 ms per token,  2361.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1572.93 ms /    63 tokens (   24.97 ms per token,    40.05 tokens per second)\n",
            "llama_print_timings:        eval time =   17800.32 ms /   199 runs   (   89.45 ms per token,    11.18 tokens per second)\n",
            "llama_print_timings:       total time =   20096.14 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     118.50 ms /   200 runs   (    0.59 ms per token,  1687.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2657.92 ms /    39 tokens (   68.15 ms per token,    14.67 tokens per second)\n",
            "llama_print_timings:        eval time =   17802.56 ms /   199 runs   (   89.46 ms per token,    11.18 tokens per second)\n",
            "llama_print_timings:       total time =   21215.30 ms /   238 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     114.84 ms /   200 runs   (    0.57 ms per token,  1741.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1472.75 ms /    60 tokens (   24.55 ms per token,    40.74 tokens per second)\n",
            "llama_print_timings:        eval time =   17782.59 ms /   199 runs   (   89.36 ms per token,    11.19 tokens per second)\n",
            "llama_print_timings:       total time =   20003.40 ms /   259 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     108.08 ms /   200 runs   (    0.54 ms per token,  1850.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1098.78 ms /    67 tokens (   16.40 ms per token,    60.98 tokens per second)\n",
            "llama_print_timings:        eval time =   17978.39 ms /   199 runs   (   90.34 ms per token,    11.07 tokens per second)\n",
            "llama_print_timings:       total time =   19826.26 ms /   266 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 2\n",
            "\n",
            "Processing batch 3 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.92 ms /   200 runs   (    0.42 ms per token,  2355.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1583.69 ms /    63 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
            "llama_print_timings:        eval time =   17882.92 ms /   199 runs   (   89.86 ms per token,    11.13 tokens per second)\n",
            "llama_print_timings:       total time =   20193.18 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     118.67 ms /   200 runs   (    0.59 ms per token,  1685.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1043.63 ms /    47 tokens (   22.20 ms per token,    45.04 tokens per second)\n",
            "llama_print_timings:        eval time =   17790.91 ms /   199 runs   (   89.40 ms per token,    11.19 tokens per second)\n",
            "llama_print_timings:       total time =   19590.99 ms /   246 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     120.62 ms /   200 runs   (    0.60 ms per token,  1658.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2818.03 ms /    48 tokens (   58.71 ms per token,    17.03 tokens per second)\n",
            "llama_print_timings:        eval time =   17833.27 ms /   199 runs   (   89.61 ms per token,    11.16 tokens per second)\n",
            "llama_print_timings:       total time =   21415.68 ms /   247 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.81 ms /   200 runs   (    0.42 ms per token,  2358.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1575.24 ms /    63 tokens (   25.00 ms per token,    39.99 tokens per second)\n",
            "llama_print_timings:        eval time =   17903.36 ms /   199 runs   (   89.97 ms per token,    11.12 tokens per second)\n",
            "llama_print_timings:       total time =   20205.96 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     121.99 ms /   200 runs   (    0.61 ms per token,  1639.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1728.08 ms /    86 tokens (   20.09 ms per token,    49.77 tokens per second)\n",
            "llama_print_timings:        eval time =   17771.84 ms /   199 runs   (   89.31 ms per token,    11.20 tokens per second)\n",
            "llama_print_timings:       total time =   20261.62 ms /   285 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 3\n",
            "\n",
            "Processing batch 4 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.73 ms /   200 runs   (    0.56 ms per token,  1790.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1633.80 ms /    63 tokens (   25.93 ms per token,    38.56 tokens per second)\n",
            "llama_print_timings:        eval time =   17869.96 ms /   199 runs   (   89.80 ms per token,    11.14 tokens per second)\n",
            "llama_print_timings:       total time =   20260.70 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     116.17 ms /   200 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1064.83 ms /    30 tokens (   35.49 ms per token,    28.17 tokens per second)\n",
            "llama_print_timings:        eval time =   17872.22 ms /   199 runs   (   89.81 ms per token,    11.13 tokens per second)\n",
            "llama_print_timings:       total time =   19689.29 ms /   229 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     117.19 ms /   200 runs   (    0.59 ms per token,  1706.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2546.93 ms /    82 tokens (   31.06 ms per token,    32.20 tokens per second)\n",
            "llama_print_timings:        eval time =   17857.23 ms /   199 runs   (   89.73 ms per token,    11.14 tokens per second)\n",
            "llama_print_timings:       total time =   21159.88 ms /   281 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.69 ms /   190 runs   (    0.59 ms per token,  1701.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1658.49 ms /    83 tokens (   19.98 ms per token,    50.05 tokens per second)\n",
            "llama_print_timings:        eval time =   16971.37 ms /   189 runs   (   89.80 ms per token,    11.14 tokens per second)\n",
            "llama_print_timings:       total time =   19351.57 ms /   272 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.64 ms /   200 runs   (    0.42 ms per token,  2362.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1577.19 ms /    63 tokens (   25.03 ms per token,    39.94 tokens per second)\n",
            "llama_print_timings:        eval time =   17897.92 ms /   199 runs   (   89.94 ms per token,    11.12 tokens per second)\n",
            "llama_print_timings:       total time =   20200.31 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 4\n",
            "\n",
            "Processing batch 5 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     118.25 ms /   200 runs   (    0.59 ms per token,  1691.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2488.56 ms /    96 tokens (   25.92 ms per token,    38.58 tokens per second)\n",
            "llama_print_timings:        eval time =   17850.92 ms /   199 runs   (   89.70 ms per token,    11.15 tokens per second)\n",
            "llama_print_timings:       total time =   21106.40 ms /   295 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.73 ms /   200 runs   (    0.56 ms per token,  1790.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1590.30 ms /    63 tokens (   25.24 ms per token,    39.62 tokens per second)\n",
            "llama_print_timings:        eval time =   17863.55 ms /   199 runs   (   89.77 ms per token,    11.14 tokens per second)\n",
            "llama_print_timings:       total time =   20212.70 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      67.47 ms /   114 runs   (    0.59 ms per token,  1689.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1323.17 ms /    73 tokens (   18.13 ms per token,    55.17 tokens per second)\n",
            "llama_print_timings:        eval time =   10027.61 ms /   113 runs   (   88.74 ms per token,    11.27 tokens per second)\n",
            "llama_print_timings:       total time =   11772.53 ms /   186 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     118.57 ms /   200 runs   (    0.59 ms per token,  1686.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1617.66 ms /    73 tokens (   22.16 ms per token,    45.13 tokens per second)\n",
            "llama_print_timings:        eval time =   17816.52 ms /   199 runs   (   89.53 ms per token,    11.17 tokens per second)\n",
            "llama_print_timings:       total time =   20195.70 ms /   272 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     118.22 ms /   200 runs   (    0.59 ms per token,  1691.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1445.12 ms /    77 tokens (   18.77 ms per token,    53.28 tokens per second)\n",
            "llama_print_timings:        eval time =   17878.86 ms /   199 runs   (   89.84 ms per token,    11.13 tokens per second)\n",
            "llama_print_timings:       total time =   20086.88 ms /   276 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 5\n",
            "\n",
            "Processing batch 6 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      88.05 ms /   149 runs   (    0.59 ms per token,  1692.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1654.22 ms /    83 tokens (   19.93 ms per token,    50.17 tokens per second)\n",
            "llama_print_timings:        eval time =   13350.45 ms /   148 runs   (   90.21 ms per token,    11.09 tokens per second)\n",
            "llama_print_timings:       total time =   15574.37 ms /   231 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     119.33 ms /   200 runs   (    0.60 ms per token,  1676.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2051.90 ms /    93 tokens (   22.06 ms per token,    45.32 tokens per second)\n",
            "llama_print_timings:        eval time =   17917.67 ms /   199 runs   (   90.04 ms per token,    11.11 tokens per second)\n",
            "llama_print_timings:       total time =   20749.13 ms /   292 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     120.56 ms /   200 runs   (    0.60 ms per token,  1658.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1570.28 ms /    81 tokens (   19.39 ms per token,    51.58 tokens per second)\n",
            "llama_print_timings:        eval time =   17898.47 ms /   199 runs   (   89.94 ms per token,    11.12 tokens per second)\n",
            "llama_print_timings:       total time =   20263.66 ms /   280 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     118.00 ms /   200 runs   (    0.59 ms per token,  1694.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3487.44 ms /    75 tokens (   46.50 ms per token,    21.51 tokens per second)\n",
            "llama_print_timings:        eval time =   18087.15 ms /   199 runs   (   90.89 ms per token,    11.00 tokens per second)\n",
            "llama_print_timings:       total time =   22372.14 ms /   274 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     117.85 ms /   200 runs   (    0.59 ms per token,  1697.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1498.77 ms /    77 tokens (   19.46 ms per token,    51.38 tokens per second)\n",
            "llama_print_timings:        eval time =   18104.44 ms /   199 runs   (   90.98 ms per token,    10.99 tokens per second)\n",
            "llama_print_timings:       total time =   20402.27 ms /   276 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 6\n",
            "\n",
            "Processing batch 7 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     112.72 ms /   200 runs   (    0.56 ms per token,  1774.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1618.44 ms /    63 tokens (   25.69 ms per token,    38.93 tokens per second)\n",
            "llama_print_timings:        eval time =   18119.49 ms /   199 runs   (   91.05 ms per token,    10.98 tokens per second)\n",
            "llama_print_timings:       total time =   20536.77 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     117.96 ms /   200 runs   (    0.59 ms per token,  1695.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3617.09 ms /    78 tokens (   46.37 ms per token,    21.56 tokens per second)\n",
            "llama_print_timings:        eval time =   17950.05 ms /   199 runs   (   90.20 ms per token,    11.09 tokens per second)\n",
            "llama_print_timings:       total time =   22361.73 ms /   277 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.75 ms /   200 runs   (    0.56 ms per token,  1789.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1599.76 ms /    63 tokens (   25.39 ms per token,    39.38 tokens per second)\n",
            "llama_print_timings:        eval time =   17967.86 ms /   199 runs   (   90.29 ms per token,    11.08 tokens per second)\n",
            "llama_print_timings:       total time =   20341.28 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     119.66 ms /   200 runs   (    0.60 ms per token,  1671.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1280.30 ms /    72 tokens (   17.78 ms per token,    56.24 tokens per second)\n",
            "llama_print_timings:        eval time =   17780.15 ms /   199 runs   (   89.35 ms per token,    11.19 tokens per second)\n",
            "llama_print_timings:       total time =   19810.09 ms /   271 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     116.68 ms /   200 runs   (    0.58 ms per token,  1714.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     711.66 ms /    38 tokens (   18.73 ms per token,    53.40 tokens per second)\n",
            "llama_print_timings:        eval time =   17861.27 ms /   199 runs   (   89.76 ms per token,    11.14 tokens per second)\n",
            "llama_print_timings:       total time =   19346.07 ms /   237 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 7\n",
            "\n",
            "Processing batch 8 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.36 ms /   200 runs   (    0.56 ms per token,  1795.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1602.95 ms /    63 tokens (   25.44 ms per token,    39.30 tokens per second)\n",
            "llama_print_timings:        eval time =   17911.47 ms /   199 runs   (   90.01 ms per token,    11.11 tokens per second)\n",
            "llama_print_timings:       total time =   20278.25 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.95 ms /   200 runs   (    0.42 ms per token,  2354.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3550.99 ms /    63 tokens (   56.36 ms per token,    17.74 tokens per second)\n",
            "llama_print_timings:        eval time =   17849.38 ms /   199 runs   (   89.70 ms per token,    11.15 tokens per second)\n",
            "llama_print_timings:       total time =   22136.91 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.23 ms /   200 runs   (    0.56 ms per token,  1798.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1609.22 ms /    63 tokens (   25.54 ms per token,    39.15 tokens per second)\n",
            "llama_print_timings:        eval time =   17816.09 ms /   199 runs   (   89.53 ms per token,    11.17 tokens per second)\n",
            "llama_print_timings:       total time =   20151.62 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     116.24 ms /   200 runs   (    0.58 ms per token,  1720.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1731.22 ms /    86 tokens (   20.13 ms per token,    49.68 tokens per second)\n",
            "llama_print_timings:        eval time =   17881.23 ms /   199 runs   (   89.86 ms per token,    11.13 tokens per second)\n",
            "llama_print_timings:       total time =   20347.89 ms /   285 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     115.30 ms /   200 runs   (    0.58 ms per token,  1734.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1569.98 ms /    68 tokens (   23.09 ms per token,    43.31 tokens per second)\n",
            "llama_print_timings:        eval time =   17796.86 ms /   199 runs   (   89.43 ms per token,    11.18 tokens per second)\n",
            "llama_print_timings:       total time =   20104.74 ms /   267 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 8\n",
            "\n",
            "Processing batch 9 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     112.16 ms /   200 runs   (    0.56 ms per token,  1783.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1568.57 ms /    63 tokens (   24.90 ms per token,    40.16 tokens per second)\n",
            "llama_print_timings:        eval time =   17939.17 ms /   199 runs   (   90.15 ms per token,    11.09 tokens per second)\n",
            "llama_print_timings:       total time =   20285.83 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.39 ms /   200 runs   (    0.56 ms per token,  1795.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   17985.49 ms /   200 runs   (   89.93 ms per token,    11.12 tokens per second)\n",
            "llama_print_timings:       total time =   18744.07 ms /   201 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     116.64 ms /   200 runs   (    0.58 ms per token,  1714.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1516.55 ms /    79 tokens (   19.20 ms per token,    52.09 tokens per second)\n",
            "llama_print_timings:        eval time =   17903.27 ms /   199 runs   (   89.97 ms per token,    11.12 tokens per second)\n",
            "llama_print_timings:       total time =   20188.45 ms /   278 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     118.93 ms /   200 runs   (    0.59 ms per token,  1681.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1454.46 ms /    77 tokens (   18.89 ms per token,    52.94 tokens per second)\n",
            "llama_print_timings:        eval time =   17880.79 ms /   199 runs   (   89.85 ms per token,    11.13 tokens per second)\n",
            "llama_print_timings:       total time =   20111.07 ms /   276 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.86 ms /   200 runs   (    0.42 ms per token,  2356.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1694.15 ms /    63 tokens (   26.89 ms per token,    37.19 tokens per second)\n",
            "llama_print_timings:        eval time =   17895.02 ms /   199 runs   (   89.92 ms per token,    11.12 tokens per second)\n",
            "llama_print_timings:       total time =   20324.56 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 9\n",
            "\n",
            "Processing batch 10 of 10\n",
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.80 ms /   200 runs   (    0.42 ms per token,  2358.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   17842.38 ms /   200 runs   (   89.21 ms per token,    11.21 tokens per second)\n",
            "llama_print_timings:       total time =   18543.90 ms /   201 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     119.96 ms /   200 runs   (    0.60 ms per token,  1667.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2861.22 ms /    48 tokens (   59.61 ms per token,    16.78 tokens per second)\n",
            "llama_print_timings:        eval time =   17798.37 ms /   199 runs   (   89.44 ms per token,    11.18 tokens per second)\n",
            "llama_print_timings:       total time =   21394.32 ms /   247 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     120.60 ms /   200 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1581.20 ms /    81 tokens (   19.52 ms per token,    51.23 tokens per second)\n",
            "llama_print_timings:        eval time =   17874.99 ms /   199 runs   (   89.82 ms per token,    11.13 tokens per second)\n",
            "llama_print_timings:       total time =   20195.63 ms /   280 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.77 ms /   200 runs   (    0.42 ms per token,  2359.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1567.04 ms /    63 tokens (   24.87 ms per token,    40.20 tokens per second)\n",
            "llama_print_timings:        eval time =   17940.17 ms /   199 runs   (   90.15 ms per token,    11.09 tokens per second)\n",
            "llama_print_timings:       total time =   20203.38 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complaint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.79 ms /   200 runs   (    0.56 ms per token,  1789.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1598.91 ms /    63 tokens (   25.38 ms per token,    39.40 tokens per second)\n",
            "llama_print_timings:        eval time =   17867.70 ms /   199 runs   (   89.79 ms per token,    11.14 tokens per second)\n",
            "llama_print_timings:       total time =   20200.14 ms /   262 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed batch 10\n",
            "\n",
            "Processing complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example - new_data['mistral_response_cleaned'] = new_data['narrative'].apply(lambda x:______ )\n",
        "new_data['mistral_response_cleaned'] = new_data['mistral_response'].apply(lambda x: mistral_response_cleaned(x))"
      ],
      "metadata": {
        "id": "U2JaUyDAv1kU"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6y7kMkW-4vgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SgNDVmav1iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plQNsfl0EDSG",
        "tags": []
      },
      "source": [
        "##### **Q3.2: Calculate the F1 score** **(1 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "7WXEgmPKEIoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d5ece7-348d-46c6-96f2-da906e205eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.54\n"
          ]
        }
      ],
      "source": [
        "# Calculate F1 score for 'product' and 'mistral_response'\n",
        "f1 = f1_score(new_data['product'],\n",
        "              new_data['mistral_response'].apply(lambda x: extract_category(x)),\n",
        "              average='micro')\n",
        "\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdtvdEnTEZcG",
        "tags": []
      },
      "source": [
        "##### **Q3.3: Share your observations on the few-shot and zero-shot prompt techniques. (1 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2YrUQkaK0uT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This few-shot example using the Mistral model achieved an F1 score of 0.54, which is lower than the previous zero-shot approach that scored 0.8.\n",
        "\n",
        "The decline in performance can be attributed to (potential?) limitations of the few-shot architecture.\n",
        "\n",
        "With zero-shot, the model used pre-trained knowledge and generalized understanding of financial complaint categories and introduced a few, specific examples. This may be introducing bias / noise leading towards  sparse interpretation or alternatively mean, better performance.\n",
        "Potential next steps could include refining the few-shot example selection, experimenting with different prompt structures, or exploring alternative few-shot learning techniques such as cross checking the performance against another LLM such as GPT."
      ],
      "metadata": {
        "id": "Fm69cq0ADAnC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vca9B37WGneH",
        "tags": []
      },
      "source": [
        "# **Section 3: Text to Text generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJlqcsdJBVZx",
        "tags": []
      },
      "source": [
        "### **Question 4: Zero-Shot Prompting for Text Summarization (5 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDFS-VMEIEZs",
        "tags": []
      },
      "source": [
        "##### **Q4.1: Define the Prompt Template, System Message, generate prompt and model response** **(3 Marks)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJoScpBlBVZx",
        "tags": []
      },
      "source": [
        "- Define a **system message** as a string and assign it to the variable system_message to generate summary of narrative in data.\n",
        "- Create a **zero shot prompt template** that incorporates the system message and user input.\n",
        "- Define **generate_prompt** function that takes both the system_message and user_input as arguments and formats them into a prompt template\n",
        "\n",
        "\n",
        "Write a Python function called **generate_mistral_response** that takes a single parameter, narrative, which represents the user's complain. Inside the function, you should perform the following tasks:\n",
        "\n",
        "\n",
        "- **Combine the system_message and narrative to create a prompt string using generate_prompt function.**\n",
        "\n",
        "*Generate a response from the Mistral model using the lcpp_llm instance with the following parameters:*\n",
        "\n",
        "- prompt should be the combined prompt string.\n",
        "- max_tokens should be set to 1200.\n",
        "- temperature should be set to 0.\n",
        "- top_p should be set to 0.95.\n",
        "- repeat_penalty should be set to 1.2.\n",
        "- top_k should be set to 50.\n",
        "- stop should be set as a list containing '/s'.\n",
        "- echo should be set to False.\n",
        "Extract and return the response text from the generated response.\n",
        "\n",
        "Don't forget to provide a value for the system_message variable before using it in the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "7PewmIuBII56"
      },
      "outputs": [],
      "source": [
        "system_message = \"Provide a concise, clear summary of the financial customer complaint, capturing the key issues, parties involved, and main concerns without unnecessary details.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt_template = \"\"\"<s>[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "\n",
        "Summarize the following customer complaint:\n",
        "```{user_message}```\n",
        "[/INST]\"\"\"\n",
        "\n",
        "def generate_prompt(system_message, user_input):\n",
        "    prompt = zero_shot_prompt_template.format(system_message=system_message, user_message=user_input)\n",
        "    return prompt\n",
        "\n",
        "def generate_mistral_response(input_text):\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    prompt = generate_prompt(system_message, input_text)\n",
        "\n",
        "    # Define the Llama model along with its parameters for generating a response\n",
        "    response = lcpp_llm(\n",
        "        prompt=prompt,\n",
        "        max_tokens=1200,\n",
        "        temperature=0,\n",
        "        top_p=0.95,\n",
        "        repeat_penalty=1.2,\n",
        "        top_k=50,\n",
        "        stop=[\"/s\"],\n",
        "        echo=False\n",
        "    )\n",
        "\n",
        "    # Extract and return the response text\n",
        "    response_text = response[\"choices\"][0][\"text\"]\n",
        "    print(response_text)\n",
        "    return response_text"
      ],
      "metadata": {
        "id": "FHdRf0ISF77e"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpiIHpThMtW6",
        "tags": []
      },
      "source": [
        "##### **Q4.2: Generate mistral_response column containing LLM generated summaries** **(1 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Fqxl54MMMBTu"
      },
      "outputs": [],
      "source": [
        "# Randomly select 30 rows\n",
        "gold_examples = data.sample(n=30 , random_state=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "1kWS3MmUMEgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb83ea8-0816-4811-fea6-8dd26e45cfb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      96.89 ms /   157 runs   (    0.62 ms per token,  1620.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4533.21 ms /   273 tokens (   16.61 ms per token,    60.22 tokens per second)\n",
            "llama_print_timings:        eval time =   14243.44 ms /   156 runs   (   91.30 ms per token,    10.95 tokens per second)\n",
            "llama_print_timings:       total time =   19418.96 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer discovered a fraudulent charge of undisclosed amount on their Capital One checking account, which was quickly canceled. The customer disputed the charge and received provisional credit pending determination. However, the claim was denied by Capital One despite several appeals and communications between the parties. The customer believes that someone intercepted and activated their debit card without authorization to make a fraudulent purchase. They also reported this incident to local police. Despite not receiving the replacement card yet, Capital One sent it and allowed its use for credit purchases without prior consent. The customer is concerned about the bank's handling of the situation and believes there has been malfeasance and gross business practices involved in sending a replacement card without authorization and allowing unauthorized usage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     184.63 ms /   298 runs   (    0.62 ms per token,  1614.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9131.13 ms /   507 tokens (   18.01 ms per token,    55.52 tokens per second)\n",
            "llama_print_timings:        eval time =   27537.21 ms /   297 runs   (   92.72 ms per token,    10.79 tokens per second)\n",
            "llama_print_timings:       total time =   37937.99 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint regarding identity theft, requesting a credit reporting agency to block certain information from their report. The dispute arose when the agency failed to promptly block the disputed information following receipt of an identity theft report. The consumer is concerned about potential damage to their credit score due to erroneous information being reported.\n",
            "\n",
            "The Consumer Reporting Agency (CRA) has the authority to decline or rescind such blocks, but must provide clear reasons for doing so and notify both the consumer and any relevant furnishers of the dispute. The CRA may also be required to block information relating to a transaction that resulted from identity theft.\n",
            "\n",
            "The CRA is obligated to promptly notify affected consumers when information has been reinstated, and must provide them with clear notice containing specific details about the disputed information. Resellers are also subject to these requirements if they file consumer reports concerning the identified consumer.\n",
            "\n",
            "Additionally, check service companies have a role in this process by reporting identity theft-related information to the CRA and verifying account information before allowing access or transactions on frozen accounts. The Fair Credit Reporting Act (FCRA) requires credit reporting agencies to prevent law enforcement agencies from accessing blocked information without proper verification of consumer authorization.\n",
            "\n",
            "Overall, the customer is seeking assurance that their identity theft report will be properly addressed and disputed information removed from their credit reports in accordance with FCRA regulations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      84.94 ms /   142 runs   (    0.60 ms per token,  1671.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4024.19 ms /   184 tokens (   21.87 ms per token,    45.72 tokens per second)\n",
            "llama_print_timings:        eval time =   12842.61 ms /   141 runs   (   91.08 ms per token,    10.98 tokens per second)\n",
            "llama_print_timings:       total time =   17435.28 ms /   325 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A USAA customer filed a complaint regarding unauthorized use of their personal information to open two delinquent credit card accounts with USAA. The customer claimed that they were personally liable for the debts, but believed that USAA was responsible for the fraudulent activity as they had not authorized the opening of these accounts. The customer provided evidence in the form of attached statements and a credit card fraud claim. USAA acknowledged the unauthorized transactions and confirmed their liability. The customer also mentioned an ongoing identity theft case and a CFPB response regarding the matter. USAA reviewed the claim, determined that fraudulent activity had occurred, made a payment to resolve the issue, and closed the accounts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     183.80 ms /   298 runs   (    0.62 ms per token,  1621.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11114.28 ms /   507 tokens (   21.92 ms per token,    45.62 tokens per second)\n",
            "llama_print_timings:        eval time =   27457.29 ms /   297 runs   (   92.45 ms per token,    10.82 tokens per second)\n",
            "llama_print_timings:       total time =   39810.57 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint regarding identity theft, requesting a credit reporting agency to block certain information from their report. The dispute arose when the agency failed to promptly block the disputed information following receipt of an identity theft report. The consumer is concerned about potential damage to their credit score due to erroneous information being reported.\n",
            "\n",
            "The Consumer Reporting Agency (CRA) has the authority to decline or rescind such blocks, but must provide clear reasons for doing so and notify both the consumer and any relevant furnishers of the dispute. The CRA may also be required to block information relating to a transaction that resulted from identity theft.\n",
            "\n",
            "The CRA is obligated to promptly notify affected consumers when information has been reinstated, and must provide them with clear notice containing specific details about the disputed information. Resellers are also subject to these requirements if they file consumer reports concerning the identified consumer.\n",
            "\n",
            "Additionally, check service companies have a role in this process by reporting identity theft-related information to the CRA and verifying account information before allowing access or transactions on frozen accounts. The Fair Credit Reporting Act (FCRA) requires credit reporting agencies to prevent law enforcement agencies from accessing blocked information without proper verification of consumer authorization.\n",
            "\n",
            "Overall, the customer is seeking assurance that their identity theft report will be properly addressed and disputed information removed from their credit reports in accordance with FCRA regulations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      49.41 ms /    87 runs   (    0.57 ms per token,  1760.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1424.96 ms /    76 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
            "llama_print_timings:        eval time =    7809.08 ms /    86 runs   (   90.80 ms per token,    11.01 tokens per second)\n",
            "llama_print_timings:       total time =    9574.69 ms /   162 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer has filed a complaint regarding multiple issues with their account openings. They mention that the balances listed for each account opening do not match, and they are concerned about potential errors or fraudulent activity. The exact number of accounts involved is unclear from the provided text, but it appears to be several based on repetition. The main parties involved are the customer and the financial institution responsible for processing these account openings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     112.08 ms /   187 runs   (    0.60 ms per token,  1668.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6533.91 ms /   422 tokens (   15.48 ms per token,    64.59 tokens per second)\n",
            "llama_print_timings:        eval time =   17104.15 ms /   186 runs   (   91.96 ms per token,    10.87 tokens per second)\n",
            "llama_print_timings:       total time =   24400.79 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint about an alleged identity theft incident, requesting a credit reporting agency to block certain information from their consumer report. The dispute arose when the agency failed to promptly block the disputed information upon receiving appropriate proof of identity theft and a copy of the identity theft report. The main concerns include the delay in blocking the information, potential damage caused by its continued presence on the report, and the consumer's right to be notified about any reinstatement or rescission of the block.\n",
            "\n",
            "The complaint also mentions that the furnisher (business providing information for the credit report) should be informed when identity theft is identified, and consumers have the right to obtain information regarding identity theft from resellers who file consumer reports. The consumer reporting agency has a responsibility to apply blocks on consumer reports in accordance with specific provisions of law, including those related to check services and access by law enforcement agencies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      68.18 ms /   114 runs   (    0.60 ms per token,  1672.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1866.59 ms /    89 tokens (   20.97 ms per token,    47.68 tokens per second)\n",
            "llama_print_timings:        eval time =   10203.48 ms /   113 runs   (   90.30 ms per token,    11.07 tokens per second)\n",
            "llama_print_timings:       total time =   12505.58 ms /   202 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A PenFed customer complained about the loan application process. The customer applied for a loan and submitted proof of income through a payment stub, account statement, tax form, and an employee work letter. PenFed requested additional documentation including deposit statements, checks, and transfer information. The customer provided a check related to legal services rendered, but PenFed questioned the legitimacy of the expense as it appeared to exceed reported paid taxes for professional services. The customer believes that PenFed is going beyond what's necessary in evaluating their income payment capacity.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.82 ms /   187 runs   (    0.60 ms per token,  1672.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6546.53 ms /   422 tokens (   15.51 ms per token,    64.46 tokens per second)\n",
            "llama_print_timings:        eval time =   17063.96 ms /   186 runs   (   91.74 ms per token,    10.90 tokens per second)\n",
            "llama_print_timings:       total time =   24373.27 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint about an alleged identity theft incident, requesting a credit reporting agency to block certain information from their consumer report. The dispute arose when the agency failed to promptly block the disputed information upon receiving appropriate proof of identity theft and a copy of the identity theft report. The main concerns include the delay in blocking the information, potential damage caused by its continued presence on the report, and the consumer's right to be notified about any reinstatement or rescission of the block.\n",
            "\n",
            "The complaint also mentions that the furnisher (business providing information for the credit report) should be informed when identity theft is identified, and consumers have the right to obtain information regarding identity theft from resellers who file consumer reports. The consumer reporting agency has a responsibility to apply blocks on consumer reports in accordance with specific provisions of law, including those related to check services and access by law enforcement agencies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     142.45 ms /   236 runs   (    0.60 ms per token,  1656.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6955.79 ms /   434 tokens (   16.03 ms per token,    62.39 tokens per second)\n",
            "llama_print_timings:        eval time =   21572.67 ms /   235 runs   (   91.80 ms per token,    10.89 tokens per second)\n",
            "llama_print_timings:       total time =   29486.26 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint about inaccurate information being reported to credit agencies due to alleged identity theft. The customer requested the blocking of related information from their credit reports. The Consumer Reporting Agency (CRA) is responsible for blocking the reporting of such information and notifying furnishers, but may decline if it determines that the request is based on a material misrepresentation or error. If the CRA rescinds the block, the consumer must be promptly notified. The affected consumer has the right to be notified in writing when the blocked information is reinstated.\n",
            "\n",
            "The CRA may also decline to block information if it determines that the consumer obtained the good or services using stolen funds or identification. In such cases, resellers are required to provide notice to consumers about the decision to file a report concerning the identified consumer. The check service company must apply verification procedures before approving transactions suspected of being related to identity theft.\n",
            "\n",
            "The CRA is obligated to prevent law enforcement agencies from accessing blocked information unless they have proper authorization or a court order, and may only do so in accordance with applicable laws and regulations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.35 ms /   187 runs   (    0.60 ms per token,  1679.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8121.39 ms /   422 tokens (   19.25 ms per token,    51.96 tokens per second)\n",
            "llama_print_timings:        eval time =   17007.37 ms /   186 runs   (   91.44 ms per token,    10.94 tokens per second)\n",
            "llama_print_timings:       total time =   25889.07 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint about an alleged identity theft incident, requesting a credit reporting agency to block certain information from their consumer report. The dispute arose when the agency failed to promptly block the disputed information upon receiving appropriate proof of identity theft and a copy of the identity theft report. The main concerns include the delay in blocking the information, potential damage caused by its continued presence on the report, and the consumer's right to be notified about any reinstatement or rescission of the block.\n",
            "\n",
            "The complaint also mentions that the furnisher (business providing information for the credit report) should be informed when identity theft is identified, and consumers have the right to obtain information regarding identity theft from resellers who file consumer reports. The consumer reporting agency has a responsibility to apply blocks on consumer reports in accordance with specific provisions of law, including those related to check services and access by law enforcement agencies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      80.38 ms /   130 runs   (    0.62 ms per token,  1617.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2692.33 ms /   149 tokens (   18.07 ms per token,    55.34 tokens per second)\n",
            "llama_print_timings:        eval time =   11617.89 ms /   129 runs   (   90.06 ms per token,    11.10 tokens per second)\n",
            "llama_print_timings:       total time =   14816.79 ms /   278 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer discovered identity theft after noticing suspicious transactions on their Equifax credit report. They believe the information was exposed due to the 2017 Equifax data breach and have reported it to both local police and the Federal Trade Commission (FTC). The customer has found multiple fraudulent accounts listed on their report, which is affecting their ability to get a job or obtain credit. They have contacted Equifax to place a fraud alert but are having difficulty communicating with the company and validating their identity. The customer requests assistance in resolving this issue and ensuring that all false information is removed from their credit report.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     103.80 ms /   169 runs   (    0.61 ms per token,  1628.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10420.50 ms /   512 tokens (   20.35 ms per token,    49.13 tokens per second)\n",
            "llama_print_timings:        eval time =   15490.46 ms /   169 runs   (   91.66 ms per token,    10.91 tokens per second)\n",
            "llama_print_timings:       total time =   26614.09 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint regarding identity theft, requesting a credit reporting agency to block certain information from their file. The dispute arose when the agency initially declined and later rescinded the block based on various conditions outlined in the Fair Credit Reporting Act (FCRA). The key issues involve the consumer's identification of fraudulent transactions leading to an identity theft report, the agency's responsibility to promptly notify furnishers and resellers about the blocked information, and the consumer's right to be notified when the block is rescinded or removed. Additionally, there are provisions for check service companies to apply verification procedures before accessing the blocked information and for law enforcement agencies to obtain it only under specific circumstances. The main concerns revolve around protecting consumers from identity theft, ensuring accurate reporting, and maintaining consumer privacy.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     111.63 ms /   187 runs   (    0.60 ms per token,  1675.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8545.46 ms /   422 tokens (   20.25 ms per token,    49.38 tokens per second)\n",
            "llama_print_timings:        eval time =   17029.21 ms /   186 runs   (   91.55 ms per token,    10.92 tokens per second)\n",
            "llama_print_timings:       total time =   26331.36 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint about an alleged identity theft incident, requesting a credit reporting agency to block certain information from their consumer report. The dispute arose when the agency failed to promptly block the disputed information upon receiving appropriate proof of identity theft and a copy of the identity theft report. The main concerns include the delay in blocking the information, potential damage caused by its continued presence on the report, and the consumer's right to be notified about any reinstatement or rescission of the block.\n",
            "\n",
            "The complaint also mentions that the furnisher (business providing information for the credit report) should be informed when identity theft is identified, and consumers have the right to obtain information regarding identity theft from resellers who file consumer reports. The consumer reporting agency has a responsibility to apply blocks on consumer reports in accordance with specific provisions of law, including those related to check services and access by law enforcement agencies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     119.88 ms /   200 runs   (    0.60 ms per token,  1668.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5465.13 ms /   234 tokens (   23.36 ms per token,    42.82 tokens per second)\n",
            "llama_print_timings:        eval time =   17976.91 ms /   199 runs   (   90.34 ms per token,    11.07 tokens per second)\n",
            "llama_print_timings:       total time =   24238.33 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A family has been experiencing financial hardships and applied for a mortgage modification. After one discrepancy was identified, the investor agreed to defer principal and extend the loan term to allow for an affordable payment. However, approximately a year later, they encountered another hardship causing loss of income. They contacted their servicer (Aurora) expressing concern that the modification had not been executed yet. Aurora informed them it was being processed by Nationstar, but they were told to reapply for the modification after several months and received two different offers. The family believes this cycle has repeated multiple times, resulting in a breach of oral contract and financial loss. They have contacted housing advocates and submitted an escalation request, alleging failure to honor the agreement. Meanwhile, they have received a letter denying their request despite investor approval for a modification due to additional medical conditions. The family is fearful of being foreclosed upon during the pandemic and urgently needs assistance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     103.61 ms /   169 runs   (    0.61 ms per token,  1631.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9600.58 ms /   512 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
            "llama_print_timings:        eval time =   15406.51 ms /   169 runs   (   91.16 ms per token,    10.97 tokens per second)\n",
            "llama_print_timings:       total time =   25687.23 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint regarding identity theft, requesting a credit reporting agency to block certain information from their file. The dispute arose when the agency initially declined and later rescinded the block based on various conditions outlined in the Fair Credit Reporting Act (FCRA). The key issues involve the consumer's identification of fraudulent transactions leading to an identity theft report, the agency's responsibility to promptly notify furnishers and resellers about the blocked information, and the consumer's right to be notified when the block is rescinded or removed. Additionally, there are provisions for check service companies to apply verification procedures before accessing the blocked information and for law enforcement agencies to obtain it only under specific circumstances. The main concerns revolve around protecting consumers from identity theft, ensuring accurate reporting, and maintaining consumer privacy.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     125.01 ms /   206 runs   (    0.61 ms per token,  1647.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8920.17 ms /   440 tokens (   20.27 ms per token,    49.33 tokens per second)\n",
            "llama_print_timings:        eval time =   18773.53 ms /   205 runs   (   91.58 ms per token,    10.92 tokens per second)\n",
            "llama_print_timings:       total time =   28515.91 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint about an alleged identity theft incident, requesting a credit reporting agency to block certain information from their report. The customer provided proof of the identity theft and requested that the reporting agency promptly notify any businesses or furnishers with relevant information. The reporting agency is required by law to block such information upon receipt of appropriate proof and may only decline or rescind the block in specific circumstances, such as material misrepresentation or error on the consumer's part.\n",
            "\n",
            "The customer was also notified promptly when any previously blocked information was reinstated. The reporting agency is responsible for maintaining and using the consumer report according to provisions regarding identity theft. Resellers are required to provide notice to consumers if they file a report concerning identified information, and check service companies must follow certain procedures before accessing blocked information.\n",
            "\n",
            "The complaint covers various sections related to identity theft reporting, blocking of information, furnisher notification, reseller obligations, consumer notifications, and access by law enforcement agencies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     112.46 ms /   187 runs   (    0.60 ms per token,  1662.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11043.94 ms /   422 tokens (   26.17 ms per token,    38.21 tokens per second)\n",
            "llama_print_timings:        eval time =   17561.65 ms /   186 runs   (   94.42 ms per token,    10.59 tokens per second)\n",
            "llama_print_timings:       total time =   29383.47 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint about an alleged identity theft incident, requesting a credit reporting agency to block certain information from their consumer report. The dispute arose when the agency failed to promptly block the disputed information upon receiving appropriate proof of identity theft and a copy of the identity theft report. The main concerns include the delay in blocking the information, potential damage caused by its continued presence on the report, and the consumer's right to be notified about any reinstatement or rescission of the block.\n",
            "\n",
            "The complaint also mentions that the furnisher (business providing information for the credit report) should be informed when identity theft is identified, and consumers have the right to obtain information regarding identity theft from resellers who file consumer reports. The consumer reporting agency has a responsibility to apply blocks on consumer reports in accordance with specific provisions of law, including those related to check services and access by law enforcement agencies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      90.77 ms /   151 runs   (    0.60 ms per token,  1663.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3036.31 ms /   195 tokens (   15.57 ms per token,    64.22 tokens per second)\n",
            "llama_print_timings:        eval time =   13603.40 ms /   150 runs   (   90.69 ms per token,    11.03 tokens per second)\n",
            "llama_print_timings:       total time =   17217.60 ms /   345 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A American Express customer complained about an unexpected credit limit reduction without prior notice. The representative initially explained the reason was due to an increase in balance on the account, but later changed their position stating it was because of increased activity on the account. The customer felt they were being penalized for taking advantage of a promotional rate and maintaining good standing with the company. They also expressed concern that American Express failed to provide proper assistance during a difficult financial situation, despite encouragement from the Consumer Financial Protection Bureau (CFPB) for financial institutions to help customers in urgent situations. The customer felt they were being put at hardship unnecessarily and criticized the representative's lack of knowledge and handling skills, as well as the absence of proper training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      85.48 ms /   143 runs   (    0.60 ms per token,  1672.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2412.78 ms /   141 tokens (   17.11 ms per token,    58.44 tokens per second)\n",
            "llama_print_timings:        eval time =   12779.00 ms /   142 runs   (   89.99 ms per token,    11.11 tokens per second)\n",
            "llama_print_timings:       total time =   15730.36 ms /   283 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer has filed a complaint about discovering fraudulent activity on their Equifax credit report, which they believe is a result of the 2017 Equifax data breach. The customer reports that they have followed the process to file a claim and are concerned about the lengthy and complicated nature of the situation. They mention feeling financial and emotional stress due to inaccurate information on their credit report, which has also resulted in being denied employment based on adverse action pertaining to the reporting of this information. The customer is seeking assistance with removing the fraudulent item from their credit report and potentially working with an attorney for compensation related to the predatory loan breach victim situation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     130.56 ms /   220 runs   (    0.59 ms per token,  1685.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9723.67 ms /   360 tokens (   27.01 ms per token,    37.02 tokens per second)\n",
            "llama_print_timings:        eval time =   20098.33 ms /   219 runs   (   91.77 ms per token,    10.90 tokens per second)\n",
            "llama_print_timings:       total time =   30693.87 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A divorced service member, who is a single mother and fell behind on her mortgage payments after losing child support, requested intervention from her employer due to their unsupportiveness. She faced difficulty in modifying the loan with the servicing company despite hardships. The situation worsened when she discovered an essential repair that she could not afford, leading her to consider a deed-in-lieu of foreclosure. However, she expressed a desire to avoid this outcome and wanted someone else to handle the sale of her house. A broker approached her with interest in buying the property but later left without completing the transaction. The loan servicing company continued to report late payments, damaging her credit score and making it difficult for her to find an attorney willing to represent her case. Despite efforts to repair her credit and make payments, she was still being reported as delinquent with late fees and interest accruing. She has been in contact with the loan servicing company several times per week, fearing that her home will be foreclosed upon despite her desire to keep it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      48.43 ms /    82 runs   (    0.59 ms per token,  1693.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1354.97 ms /    74 tokens (   18.31 ms per token,    54.61 tokens per second)\n",
            "llama_print_timings:        eval time =    7221.06 ms /    81 runs   (   89.15 ms per token,    11.22 tokens per second)\n",
            "llama_print_timings:       total time =    8872.11 ms /   155 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer is reporting an identity theft issue with TransUnion, regarding multiple disputed accounts on their credit report. The parties involved are the customer and TransUnion. The main concerns include unauthorized use of the customer's personal information to open several accounts under different account names and original creditors. The customer has been trying to contact TransUnion for resolution but hasn't received a satisfactory response yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      69.16 ms /   116 runs   (    0.60 ms per token,  1677.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9007.95 ms /   338 tokens (   26.65 ms per token,    37.52 tokens per second)\n",
            "llama_print_timings:        eval time =   10857.61 ms /   115 runs   (   94.41 ms per token,    10.59 tokens per second)\n",
            "llama_print_timings:       total time =   20342.13 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer is disputing inaccurate information on their USDOEXXXX account reported by Equifax. The key issues include inconsistent reporting dates, high credit balances and limits, a missing account dispute comment from Equifax, an invalid account number listed, and the continued reporting of a past due balance violation despite it being resolved. The customer has provided evidence to verify the information but the company refuses to make changes, which they believe is in violation of the Fair Credit Reporting Act (FCRA) and is negatively impacting their credit score.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      83.06 ms /   133 runs   (    0.62 ms per token,  1601.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2084.90 ms /   113 tokens (   18.45 ms per token,    54.20 tokens per second)\n",
            "llama_print_timings:        eval time =   11981.98 ms /   132 runs   (   90.77 ms per token,    11.02 tokens per second)\n",
            "llama_print_timings:       total time =   14592.32 ms /   245 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer has filed a complaint about suspected identity theft, as someone has used their personal information to submit fraudulent credit applications and open several unauthorized accounts with Equifax. The customer has disputed this information multiple times and claims they have been told that the requested information was sent via certified mail but has not received it. They are concerned that Equifax has failed to conduct an adequate investigation, refusing to block usage of the fraudulent account. The customer is also reporting possible violations of both the Fair Credit Reporting Act and Fair Debt Collection Practices Act. Additionally, they plan to contact their state's Attorney General for further assistance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      60.64 ms /   100 runs   (    0.61 ms per token,  1649.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2186.79 ms /   135 tokens (   16.20 ms per token,    61.73 tokens per second)\n",
            "llama_print_timings:        eval time =    8897.24 ms /    99 runs   (   89.87 ms per token,    11.13 tokens per second)\n",
            "llama_print_timings:       total time =   11473.39 ms /   234 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer has filed a complaint about a bank's handling of an investigation regarding a transaction dispute on their card. The key issues include the bank's response time, lack of clear communication, and refusal to provide supporting documentation. The main concerns are the cardholder's belief that they were owed money but were not provided proof, and frustration with the bank's unwillingness to permanently credit their account or close it due to an alleged delinquency on their report.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     109.75 ms /   187 runs   (    0.59 ms per token,  1703.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6556.43 ms /   292 tokens (   22.45 ms per token,    44.54 tokens per second)\n",
            "llama_print_timings:        eval time =   16909.58 ms /   186 runs   (   90.91 ms per token,    11.00 tokens per second)\n",
            "llama_print_timings:       total time =   24181.35 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer named Robert placed two orders on different days, both with two-day shipping and a total of $USD value. However, he only received part of the first order several weeks later due to high demand and unusually large order volume. Robert followed up via email for updates but was informed that his orders were being shipped in the order they were placed on a first come, first served basis. He expressed concern about losing his place in line and requested cancellation of one of the orders. The company agreed to cancel and issued a refund for the cancelled item. However, Robert noticed discrepancies between his bank statement and the transaction records provided by the company. He disputed the charges with his credit card issuer, Capital One, who ruled in favor of the customer and removed the purchases from Robert's account. The company then made purchase adjustments to reflect the cancelled order and refunded the corresponding amounts to Robert.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     113.59 ms /   187 runs   (    0.61 ms per token,  1646.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8019.95 ms /   422 tokens (   19.00 ms per token,    52.62 tokens per second)\n",
            "llama_print_timings:        eval time =   18380.42 ms /   186 runs   (   98.82 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =   27225.05 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint about an alleged identity theft incident, requesting a credit reporting agency to block certain information from their consumer report. The dispute arose when the agency failed to promptly block the disputed information upon receiving appropriate proof of identity theft and a copy of the identity theft report. The main concerns include the delay in blocking the information, potential damage caused by its continued presence on the report, and the consumer's right to be notified about any reinstatement or rescission of the block.\n",
            "\n",
            "The complaint also mentions that the furnisher (business providing information for the credit report) should be informed when identity theft is identified, and consumers have the right to obtain information regarding identity theft from resellers who file consumer reports. The consumer reporting agency has a responsibility to apply blocks on consumer reports in accordance with specific provisions of law, including those related to check services and access by law enforcement agencies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      63.16 ms /   108 runs   (    0.58 ms per token,  1709.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1844.21 ms /   105 tokens (   17.56 ms per token,    56.93 tokens per second)\n",
            "llama_print_timings:        eval time =   10325.61 ms /   107 runs   (   96.50 ms per token,    10.36 tokens per second)\n",
            "llama_print_timings:       total time =   12595.74 ms /   212 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The customer is a victim of identity theft, with fraudulent transactions and personal information appearing on their credit reports from TransUnion. Specifically mentioned are account numbers belonging to HealthFlex (hlthfrxxxxxxxxx) and an unspecified collection agency (XXXXXXX). The customer requests that the incorrect information be removed pursuant to the Fair Credit Reporting Act, and asks for contact details of the entities involved in order to provide necessary notifications. They also ask for their credit report information to be blocked temporarily.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     103.94 ms /   167 runs   (    0.62 ms per token,  1606.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2907.12 ms /   154 tokens (   18.88 ms per token,    52.97 tokens per second)\n",
            "llama_print_timings:        eval time =   15244.44 ms /   166 runs   (   91.83 ms per token,    10.89 tokens per second)\n",
            "llama_print_timings:       total time =   18792.76 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The customer is a victim of identity theft, with unauthorized transactions appearing on their Equifax credit report. They have been trying to resolve the issue for an extended period and find it complicated and time-consuming. The customer believes that these issues stem from the 2017 Equifax data breach. They are concerned about negative information affecting their ability to apply for credit, including being denied a first-time credit card application. Additionally, they mention that the process has caused significant financial and emotional stress, and in some cases, have prevented them from getting a job due to adverse actions based on incorrect reporting. The customer is currently working with an attorney specializing in predatory loans and breach victim compensation while carefully reviewing their credit file for any discrepancies related to the disputed account.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =     183.00 ms /   298 runs   (    0.61 ms per token,  1628.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8369.72 ms /   507 tokens (   16.51 ms per token,    60.58 tokens per second)\n",
            "llama_print_timings:        eval time =   27472.11 ms /   297 runs   (   92.50 ms per token,    10.81 tokens per second)\n",
            "llama_print_timings:       total time =   37022.92 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A customer filed a complaint regarding identity theft, requesting a credit reporting agency to block certain information from their report. The dispute arose when the agency failed to promptly block the disputed information following receipt of an identity theft report. The consumer is concerned about potential damage to their credit score due to erroneous information being reported.\n",
            "\n",
            "The Consumer Reporting Agency (CRA) has the authority to decline or rescind such blocks, but must provide clear reasons for doing so and notify both the consumer and any relevant furnishers of the dispute. The CRA may also be required to block information relating to a transaction that resulted from identity theft.\n",
            "\n",
            "The CRA is obligated to promptly notify affected consumers when information has been reinstated, and must provide them with clear notice containing specific details about the disputed information. Resellers are also subject to these requirements if they file consumer reports concerning the identified consumer.\n",
            "\n",
            "Additionally, check service companies have a role in this process by reporting identity theft-related information to the CRA and verifying account information before allowing access or transactions on frozen accounts. The Fair Credit Reporting Act (FCRA) requires credit reporting agencies to prevent law enforcement agencies from accessing blocked information without proper verification of consumer authorization.\n",
            "\n",
            "Overall, the customer is seeking assurance that their identity theft report will be properly addressed and disputed information removed from their credit reports in accordance with FCRA regulations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    1323.53 ms\n",
            "llama_print_timings:      sample time =      70.27 ms /   116 runs   (    0.61 ms per token,  1650.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1877.08 ms /    96 tokens (   19.55 ms per token,    51.14 tokens per second)\n",
            "llama_print_timings:        eval time =   10318.47 ms /   116 runs   (   88.95 ms per token,    11.24 tokens per second)\n",
            "llama_print_timings:       total time =   12618.37 ms /   212 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A mother called to report an unauthorized user was removed from her credit line, which negatively affected her credit score. The party involved is Experian, the credit reporting agency. Her main concern is that she needs a good credit score to refinance her home as her husband recently lost his job and she's having difficulty making ends meet with just her nurse salary. She tried disputing the issue online through Experian but was unable to get in touch with a representative. She requests assistance in getting Experian to reflect the proper credit score change as soon as possible.\n"
          ]
        }
      ],
      "source": [
        "# example - new_data['mistral_response_cleaned'] = new_data['narrative'].apply(lambda x:______ )\n",
        "gold_examples['mistral_response'] = gold_examples['narrative'].apply(lambda x: generate_mistral_response(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl-5fRKbND2n",
        "tags": []
      },
      "source": [
        "##### **Q4.3: Evaluate bert score** **(1 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "H6SqvLIeMVN-"
      },
      "outputs": [],
      "source": [
        "def evaluate_score(test_data, scorer, bert_score=False):\n",
        "\n",
        "    \"\"\"\n",
        "    Return the ROUGE score or BERTScore for predictions on gold examples\n",
        "    For each example we make a prediction using the prompt.\n",
        "    Gold summaries and the AI generated summaries are aggregated into lists.\n",
        "    These lists are used by the corresponding scorers to compute metrics.\n",
        "    Since BERTScore is computed for each candidate-reference pair, we take the\n",
        "    average F1 score across the gold examples.\n",
        "\n",
        "    Args:\n",
        "        prompt (List): list of messages in the Open AI prompt format\n",
        "        gold_examples (str): JSON string with list of gold examples\n",
        "        scorer (function): Scorer function used to compute the ROUGE score or the\n",
        "                           BERTScore\n",
        "        bert_score (boolean): A flag variable that indicates if BERTScore should\n",
        "                              be used as the metric.\n",
        "\n",
        "    Output:\n",
        "        score (float): BERTScore or ROUGE score computed by comparing model predictions\n",
        "                       with ground truth\n",
        "    \"\"\"\n",
        "\n",
        "    model_predictions = test_data['mistral_response'].tolist()\n",
        "    ground_truths = test_data['summary'].tolist()\n",
        "    if bert_score:\n",
        "        score = scorer.compute(\n",
        "            predictions=model_predictions,\n",
        "            references=ground_truths,\n",
        "            lang=\"en\",\n",
        "            rescale_with_baseline=True\n",
        "        )\n",
        "\n",
        "        return sum(score['f1'])/len(score['f1'])\n",
        "    else:\n",
        "        return scorer.compute(\n",
        "            predictions=model_predictions,\n",
        "            references=ground_truths\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "4T4k6rA_MlS-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "365aa6f3b79e4ecd92859735be75987d",
            "e750b0642c8c41b69e410e088f78e980",
            "4d7a701e37074f0f8a402d3e1def9aea",
            "77410cf6212a4232a4f9ee3452a3c1d3",
            "b74072403b9c47a085b5d80bab3defcf",
            "9e84f059fe924c36a15bedb2232c5c6e",
            "db82c45aadfb47e1acde3ab5342b5a42",
            "83ef14fbf3874379a462d2bda147b090",
            "1b7e25d87d6a492abd72a5889455ae4d",
            "3a282e727cec47a6a2a9a13a1ca766c9",
            "576108f7dff944b5974ac9b0193fa2dd"
          ]
        },
        "outputId": "e4a5d373-8c86-47b3-eea1-9ae0fcbae9b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "365aa6f3b79e4ecd92859735be75987d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the BERTScore evaluator\n",
        "bert_scorer = evaluate.load(\"bertscore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ikncTGPBNPRb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91,
          "referenced_widgets": [
            "43d7c4a533884a3381c4719139d9ffe1",
            "5d8b4e07f7f54498b7683c89a2a4abc9",
            "7371c78fea634d8cae71b5eca791c062",
            "fc9a20abe4674b9587a6b5822bb20aa8",
            "c37cfc2e9dc145c4a1c1adc8b8b66be5",
            "7cb4bfe844984239bc8e197ee9ebad38",
            "67b2a3ce251e41218ec4f0c5873e3d45",
            "c6c197ff33734b7f8f427addaf9f833d",
            "af5db1aca50843b6b2b4162180929643",
            "d1d07cdbad3245a0a74d9d98819d4348",
            "750918785aa148cd82304e0392da9484",
            "b1f3bf0378544511a26eae3a909f252b",
            "dc5a6a60c142470690310b24c35cfe5b",
            "e70563070cc74501abbc34118df33b1a",
            "e8cf1bdf7f8c486d8dc01a76666600d7",
            "0aa2b57868de42d8ae4b1d6563cbccbd",
            "5ee84cc290264a1e8a3d2d9626b265d3",
            "f491d18d25c34da68127f9ada9d65713",
            "5cc0ceeede89476f9018f3b9e6bea60d",
            "21da379f44ac4b749dd85373358e1e1b",
            "af1f519f6e2745a0b2f617ea37815361",
            "6eff8b6c9a8c47b39b1551a646591053",
            "52a92b828c724039ad66f91cf3573c31",
            "3f3c19882d05423c9feb5e7338704a91",
            "091e4bc022a5411b8f4027bff82c0376",
            "6b1f93ea47d7432e903bac89da61c1c8",
            "7a056ffd66ee4da792738a7ad565d339",
            "6033025b1d9247f6884de688f5c26d39",
            "3d0cab260f034345a11ba5212943b8c8",
            "987577634d6c4e7a88e202689bb9af53",
            "9173fc2674b249e2863fa8b743445537",
            "418030e7849d4089b707174a7ec7c3d6",
            "c8c3e99b36c545499c146bd577fa5c7c",
            "be9eab4fb0e04442bbdc068faca0b5f0",
            "46f12a60e6fb4b0c89108a75efc6b045",
            "ce9be4b676354628a89e9a73a6cc0582",
            "27d6b8fe0349434290e5d6556f9d1cfa",
            "78b2027116da48b1af9bfd2bd948fc7c",
            "beb7d20a497f4e22b6ef182d70aa671e",
            "5ef05dd08f9e4a659133adf47d7daca1",
            "7561743a5dfa4fc087bc90a8513d9d04",
            "fc0afd64d156442a9f7234bdbf814aa1",
            "e28c9b15a2ff49cebcbc756e045a860c",
            "6d477e08cff641ba879436cb713818fa",
            "8d05404309d14a77b71da3b71b4fe009",
            "7acc04c37f874b7ca41aeec18dd7dcb5",
            "d53f8d8a3f6440148257debe26a5fe9d",
            "7a8a8b82ae9b4942a107a3f147a70d0e",
            "e6b5370a94aa4c1680b69a7ed4d4c68e",
            "f7b4447d8c1e4f0985f8c778aa617e61",
            "78cb25ec180745659514c8d8c2661f5a",
            "1f6f22e7d4704e08a25cf51442a24410",
            "88ea5a0c106446be8097dccc2a87693d",
            "7cad93aa8234426bbd4a9f22462bcea5",
            "3a33ebd2a46b4d5987d908e7e37b7ac1",
            "e0bde4482461411296f08828b448de2f",
            "ead70299c6c74954b28dbba3cd5375d8",
            "2bd3b7b341be48cbbcb0418c04539e1e",
            "20bd81230ef44af2aaac083ed26b0d7f",
            "6bfae96635cf4fc193c73832b00e5507",
            "11a7f0fe45124eefae05e250a9402637",
            "a948696914a645c28a2097acf5494833",
            "5c99dda1c1fe4d3c985b0be52f3a77b2",
            "a5869c8cab2743f894b4827e37af4166",
            "feb18b116c8143e984fd5e39f0abd8bb",
            "1bfde952688a494ca21e9f04ef5b2557"
          ]
        },
        "outputId": "3708c681-0bbf-46c2-b092-87e10be56aa3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43d7c4a533884a3381c4719139d9ffe1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1f3bf0378544511a26eae3a909f252b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52a92b828c724039ad66f91cf3573c31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be9eab4fb0e04442bbdc068faca0b5f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d05404309d14a77b71da3b71b4fe009"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0bde4482461411296f08828b448de2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore: 0.3167718638976415\n"
          ]
        }
      ],
      "source": [
        "# Calculate BERTScore\n",
        "score = evaluate_score(\n",
        "    gold_examples,\n",
        "    bert_scorer,\n",
        "    bert_score=True\n",
        ")\n",
        "\n",
        "print(f'BERTScore: {score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The BERTScore - 0.317 is relatively low since BERTScore has ranges from 0 to 1, with higher values indicating greater similarity between the generated and reference summaries. A score of 0.317 suggests the model - generated summaries could be struggling with finding the 'semantic similarity' to the original summaries.\n",
        "\n",
        "There could also be differences or variations in how the model is captururing and interpreting key sections of the narratives compared to the human originated summaries."
      ],
      "metadata": {
        "id": "Cvhb8fHcK-zs"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70ab1170a3d14723b8fa2bca67322e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1ea0f8bb91b47b28537735ec1295760",
              "IPY_MODEL_61fc2c3474404138a60c56efb099b312",
              "IPY_MODEL_00bd676db823477689089dda1d3ed4e5"
            ],
            "layout": "IPY_MODEL_45d6159bc2e8498ba4fc6ec9a186b6da",
            "tabbable": null,
            "tooltip": null
          }
        },
        "d1ea0f8bb91b47b28537735ec1295760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_534c1c2a9600466383ae155dfc80a69a",
            "placeholder": "​",
            "style": "IPY_MODEL_84ea1d6643b54b59ad297c0de014384e",
            "tabbable": null,
            "tooltip": null,
            "value": "mistral-7b-instruct-v0.2.Q5_K_M.gguf: 100%"
          }
        },
        "61fc2c3474404138a60c56efb099b312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bef2c7a21339412fa6d3cbc5fc2dc0f4",
            "max": 5131409696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd41be5d2c7d41b198e7d40ffd8e8265",
            "tabbable": null,
            "tooltip": null,
            "value": 5131409696
          }
        },
        "00bd676db823477689089dda1d3ed4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_af5c8967257e4d56893e2550aa1f3673",
            "placeholder": "​",
            "style": "IPY_MODEL_fdb7acfc57f84bea86c8feed75b73b65",
            "tabbable": null,
            "tooltip": null,
            "value": " 5.13G/5.13G [02:02&lt;00:00, 41.8MB/s]"
          }
        },
        "45d6159bc2e8498ba4fc6ec9a186b6da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534c1c2a9600466383ae155dfc80a69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ea1d6643b54b59ad297c0de014384e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "bef2c7a21339412fa6d3cbc5fc2dc0f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd41be5d2c7d41b198e7d40ffd8e8265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af5c8967257e4d56893e2550aa1f3673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb7acfc57f84bea86c8feed75b73b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "365aa6f3b79e4ecd92859735be75987d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e750b0642c8c41b69e410e088f78e980",
              "IPY_MODEL_4d7a701e37074f0f8a402d3e1def9aea",
              "IPY_MODEL_77410cf6212a4232a4f9ee3452a3c1d3"
            ],
            "layout": "IPY_MODEL_b74072403b9c47a085b5d80bab3defcf",
            "tabbable": null,
            "tooltip": null
          }
        },
        "e750b0642c8c41b69e410e088f78e980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9e84f059fe924c36a15bedb2232c5c6e",
            "placeholder": "​",
            "style": "IPY_MODEL_db82c45aadfb47e1acde3ab5342b5a42",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading builder script: 100%"
          }
        },
        "4d7a701e37074f0f8a402d3e1def9aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_83ef14fbf3874379a462d2bda147b090",
            "max": 7950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b7e25d87d6a492abd72a5889455ae4d",
            "tabbable": null,
            "tooltip": null,
            "value": 7950
          }
        },
        "77410cf6212a4232a4f9ee3452a3c1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3a282e727cec47a6a2a9a13a1ca766c9",
            "placeholder": "​",
            "style": "IPY_MODEL_576108f7dff944b5974ac9b0193fa2dd",
            "tabbable": null,
            "tooltip": null,
            "value": " 7.95k/7.95k [00:00&lt;00:00, 680kB/s]"
          }
        },
        "b74072403b9c47a085b5d80bab3defcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e84f059fe924c36a15bedb2232c5c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db82c45aadfb47e1acde3ab5342b5a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "83ef14fbf3874379a462d2bda147b090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b7e25d87d6a492abd72a5889455ae4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a282e727cec47a6a2a9a13a1ca766c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "576108f7dff944b5974ac9b0193fa2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "43d7c4a533884a3381c4719139d9ffe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d8b4e07f7f54498b7683c89a2a4abc9",
              "IPY_MODEL_7371c78fea634d8cae71b5eca791c062",
              "IPY_MODEL_fc9a20abe4674b9587a6b5822bb20aa8"
            ],
            "layout": "IPY_MODEL_c37cfc2e9dc145c4a1c1adc8b8b66be5",
            "tabbable": null,
            "tooltip": null
          }
        },
        "5d8b4e07f7f54498b7683c89a2a4abc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7cb4bfe844984239bc8e197ee9ebad38",
            "placeholder": "​",
            "style": "IPY_MODEL_67b2a3ce251e41218ec4f0c5873e3d45",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7371c78fea634d8cae71b5eca791c062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c6c197ff33734b7f8f427addaf9f833d",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af5db1aca50843b6b2b4162180929643",
            "tabbable": null,
            "tooltip": null,
            "value": 25
          }
        },
        "fc9a20abe4674b9587a6b5822bb20aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d1d07cdbad3245a0a74d9d98819d4348",
            "placeholder": "​",
            "style": "IPY_MODEL_750918785aa148cd82304e0392da9484",
            "tabbable": null,
            "tooltip": null,
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.22kB/s]"
          }
        },
        "c37cfc2e9dc145c4a1c1adc8b8b66be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb4bfe844984239bc8e197ee9ebad38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b2a3ce251e41218ec4f0c5873e3d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c6c197ff33734b7f8f427addaf9f833d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af5db1aca50843b6b2b4162180929643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1d07cdbad3245a0a74d9d98819d4348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750918785aa148cd82304e0392da9484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b1f3bf0378544511a26eae3a909f252b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc5a6a60c142470690310b24c35cfe5b",
              "IPY_MODEL_e70563070cc74501abbc34118df33b1a",
              "IPY_MODEL_e8cf1bdf7f8c486d8dc01a76666600d7"
            ],
            "layout": "IPY_MODEL_0aa2b57868de42d8ae4b1d6563cbccbd",
            "tabbable": null,
            "tooltip": null
          }
        },
        "dc5a6a60c142470690310b24c35cfe5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5ee84cc290264a1e8a3d2d9626b265d3",
            "placeholder": "​",
            "style": "IPY_MODEL_f491d18d25c34da68127f9ada9d65713",
            "tabbable": null,
            "tooltip": null,
            "value": "config.json: 100%"
          }
        },
        "e70563070cc74501abbc34118df33b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5cc0ceeede89476f9018f3b9e6bea60d",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21da379f44ac4b749dd85373358e1e1b",
            "tabbable": null,
            "tooltip": null,
            "value": 482
          }
        },
        "e8cf1bdf7f8c486d8dc01a76666600d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_af1f519f6e2745a0b2f617ea37815361",
            "placeholder": "​",
            "style": "IPY_MODEL_6eff8b6c9a8c47b39b1551a646591053",
            "tabbable": null,
            "tooltip": null,
            "value": " 482/482 [00:00&lt;00:00, 43.0kB/s]"
          }
        },
        "0aa2b57868de42d8ae4b1d6563cbccbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ee84cc290264a1e8a3d2d9626b265d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f491d18d25c34da68127f9ada9d65713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "5cc0ceeede89476f9018f3b9e6bea60d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21da379f44ac4b749dd85373358e1e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af1f519f6e2745a0b2f617ea37815361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eff8b6c9a8c47b39b1551a646591053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "52a92b828c724039ad66f91cf3573c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f3c19882d05423c9feb5e7338704a91",
              "IPY_MODEL_091e4bc022a5411b8f4027bff82c0376",
              "IPY_MODEL_6b1f93ea47d7432e903bac89da61c1c8"
            ],
            "layout": "IPY_MODEL_7a056ffd66ee4da792738a7ad565d339",
            "tabbable": null,
            "tooltip": null
          }
        },
        "3f3c19882d05423c9feb5e7338704a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6033025b1d9247f6884de688f5c26d39",
            "placeholder": "​",
            "style": "IPY_MODEL_3d0cab260f034345a11ba5212943b8c8",
            "tabbable": null,
            "tooltip": null,
            "value": "vocab.json: 100%"
          }
        },
        "091e4bc022a5411b8f4027bff82c0376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_987577634d6c4e7a88e202689bb9af53",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9173fc2674b249e2863fa8b743445537",
            "tabbable": null,
            "tooltip": null,
            "value": 898823
          }
        },
        "6b1f93ea47d7432e903bac89da61c1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_418030e7849d4089b707174a7ec7c3d6",
            "placeholder": "​",
            "style": "IPY_MODEL_c8c3e99b36c545499c146bd577fa5c7c",
            "tabbable": null,
            "tooltip": null,
            "value": " 899k/899k [00:00&lt;00:00, 34.6MB/s]"
          }
        },
        "7a056ffd66ee4da792738a7ad565d339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6033025b1d9247f6884de688f5c26d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0cab260f034345a11ba5212943b8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "987577634d6c4e7a88e202689bb9af53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9173fc2674b249e2863fa8b743445537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "418030e7849d4089b707174a7ec7c3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c3e99b36c545499c146bd577fa5c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "be9eab4fb0e04442bbdc068faca0b5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46f12a60e6fb4b0c89108a75efc6b045",
              "IPY_MODEL_ce9be4b676354628a89e9a73a6cc0582",
              "IPY_MODEL_27d6b8fe0349434290e5d6556f9d1cfa"
            ],
            "layout": "IPY_MODEL_78b2027116da48b1af9bfd2bd948fc7c",
            "tabbable": null,
            "tooltip": null
          }
        },
        "46f12a60e6fb4b0c89108a75efc6b045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_beb7d20a497f4e22b6ef182d70aa671e",
            "placeholder": "​",
            "style": "IPY_MODEL_5ef05dd08f9e4a659133adf47d7daca1",
            "tabbable": null,
            "tooltip": null,
            "value": "merges.txt: 100%"
          }
        },
        "ce9be4b676354628a89e9a73a6cc0582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7561743a5dfa4fc087bc90a8513d9d04",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc0afd64d156442a9f7234bdbf814aa1",
            "tabbable": null,
            "tooltip": null,
            "value": 456318
          }
        },
        "27d6b8fe0349434290e5d6556f9d1cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e28c9b15a2ff49cebcbc756e045a860c",
            "placeholder": "​",
            "style": "IPY_MODEL_6d477e08cff641ba879436cb713818fa",
            "tabbable": null,
            "tooltip": null,
            "value": " 456k/456k [00:00&lt;00:00, 2.15MB/s]"
          }
        },
        "78b2027116da48b1af9bfd2bd948fc7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb7d20a497f4e22b6ef182d70aa671e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef05dd08f9e4a659133adf47d7daca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "7561743a5dfa4fc087bc90a8513d9d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc0afd64d156442a9f7234bdbf814aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e28c9b15a2ff49cebcbc756e045a860c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d477e08cff641ba879436cb713818fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "8d05404309d14a77b71da3b71b4fe009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7acc04c37f874b7ca41aeec18dd7dcb5",
              "IPY_MODEL_d53f8d8a3f6440148257debe26a5fe9d",
              "IPY_MODEL_7a8a8b82ae9b4942a107a3f147a70d0e"
            ],
            "layout": "IPY_MODEL_e6b5370a94aa4c1680b69a7ed4d4c68e",
            "tabbable": null,
            "tooltip": null
          }
        },
        "7acc04c37f874b7ca41aeec18dd7dcb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f7b4447d8c1e4f0985f8c778aa617e61",
            "placeholder": "​",
            "style": "IPY_MODEL_78cb25ec180745659514c8d8c2661f5a",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer.json: 100%"
          }
        },
        "d53f8d8a3f6440148257debe26a5fe9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1f6f22e7d4704e08a25cf51442a24410",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88ea5a0c106446be8097dccc2a87693d",
            "tabbable": null,
            "tooltip": null,
            "value": 1355863
          }
        },
        "7a8a8b82ae9b4942a107a3f147a70d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7cad93aa8234426bbd4a9f22462bcea5",
            "placeholder": "​",
            "style": "IPY_MODEL_3a33ebd2a46b4d5987d908e7e37b7ac1",
            "tabbable": null,
            "tooltip": null,
            "value": " 1.36M/1.36M [00:00&lt;00:00, 25.0MB/s]"
          }
        },
        "e6b5370a94aa4c1680b69a7ed4d4c68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b4447d8c1e4f0985f8c778aa617e61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78cb25ec180745659514c8d8c2661f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "1f6f22e7d4704e08a25cf51442a24410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88ea5a0c106446be8097dccc2a87693d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cad93aa8234426bbd4a9f22462bcea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a33ebd2a46b4d5987d908e7e37b7ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e0bde4482461411296f08828b448de2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ead70299c6c74954b28dbba3cd5375d8",
              "IPY_MODEL_2bd3b7b341be48cbbcb0418c04539e1e",
              "IPY_MODEL_20bd81230ef44af2aaac083ed26b0d7f"
            ],
            "layout": "IPY_MODEL_6bfae96635cf4fc193c73832b00e5507",
            "tabbable": null,
            "tooltip": null
          }
        },
        "ead70299c6c74954b28dbba3cd5375d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_11a7f0fe45124eefae05e250a9402637",
            "placeholder": "​",
            "style": "IPY_MODEL_a948696914a645c28a2097acf5494833",
            "tabbable": null,
            "tooltip": null,
            "value": "model.safetensors: 100%"
          }
        },
        "2bd3b7b341be48cbbcb0418c04539e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5c99dda1c1fe4d3c985b0be52f3a77b2",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5869c8cab2743f894b4827e37af4166",
            "tabbable": null,
            "tooltip": null,
            "value": 1421700479
          }
        },
        "20bd81230ef44af2aaac083ed26b0d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_feb18b116c8143e984fd5e39f0abd8bb",
            "placeholder": "​",
            "style": "IPY_MODEL_1bfde952688a494ca21e9f04ef5b2557",
            "tabbable": null,
            "tooltip": null,
            "value": " 1.42G/1.42G [00:06&lt;00:00, 228MB/s]"
          }
        },
        "6bfae96635cf4fc193c73832b00e5507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a7f0fe45124eefae05e250a9402637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a948696914a645c28a2097acf5494833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "5c99dda1c1fe4d3c985b0be52f3a77b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5869c8cab2743f894b4827e37af4166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "feb18b116c8143e984fd5e39f0abd8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfde952688a494ca21e9f04ef5b2557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}